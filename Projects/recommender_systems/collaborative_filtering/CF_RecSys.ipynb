{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef0904d3",
   "metadata": {},
   "source": [
    "[ Credits ] : Andrew Ng, DeepLearning.AI, Machine Learning Specialization on Coursera"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e6b889",
   "metadata": {},
   "source": [
    "# Collaborative Filtering Recommender System for Movie Recommendations\n",
    "\n",
    "Collaborative filtering (CF) is a popular technique used in recommendation systems. It operates under the assumption that if two users agree on one issue, they will likely agree on others as well. In the context of movie recommendations, if two users both liked certain movies, they are likely to share similar tastes in other movies as well.\n",
    "\n",
    "There are two primary types of collaborative filtering:\n",
    "\n",
    "1. **User-Based CF**: This method finds users that are similar to the targeted user and recommends items based on what those similar users liked.\n",
    "2. **Item-Based CF**: Instead of looking at user similarities, this approach finds similarities between items. So if a user liked a particular item, other items that are similar to it will be recommended.\n",
    "\n",
    "## Why use Collaborative Filtering?\n",
    "\n",
    "1. **Personalization**: Collaborative filtering offers a personalized user experience. Each user gets recommendations based on their unique tastes and preferences.\n",
    "2. **Scalability**: Modern collaborative filtering methods can handle large datasets efficiently, making them ideal for today's internet-scale applications.\n",
    "3. **No need for item metadata**: Unlike content-based recommendation systems, CF doesn't require any information about the items. It works purely based on user-item interactions.\n",
    "4. **Adaptability**: Collaborative filtering models can adapt over time. As more users interact with items, the system becomes more refined and accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0e4328",
   "metadata": {},
   "source": [
    "## Notation\n",
    "|General <br />  Notation  | Description| Python (if any) |\n",
    "|:-------------|:------------------------------------------------------------||\n",
    "| $r(i,j)$     | scalar; = 1  if user j rated movie i,  = 0  otherwise             ||\n",
    "| $y(i,j)$     | scalar; = rating given by user j on movie  i    (if r(i,j) = 1 is defined) ||\n",
    "|$\\mathbf{w}^{(j)}$ | vector; parameters for user j ||\n",
    "|$b^{(j)}$     |  scalar; parameter for user j ||\n",
    "| $\\mathbf{x}^{(i)}$ |   vector; feature ratings for movie i        ||     \n",
    "| $n_u$        | number of users |num_users|\n",
    "| $n_m$        | number of movies | num_movies |\n",
    "| $n$          | number of features | num_features                    |\n",
    "| $\\mathbf{X}$ |  matrix of vectors $\\mathbf{x}^{(i)}$         | X |\n",
    "| $\\mathbf{W}$ |  matrix of vectors $\\mathbf{w}^{(j)}$         | W |\n",
    "| $\\mathbf{b}$ |  vector of bias parameters $b^{(j)}$ | b |\n",
    "| $\\mathbf{R}$ | matrix of elements $r(i,j)$                    | R |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d6aaedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a34efc3",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af812e19",
   "metadata": {},
   "source": [
    "The data set is derived from the [MovieLens \"ml-latest-small\"](https://grouplens.org/datasets/movielens/latest/) dataset. It contains 9724 movies and 610 users.\n",
    "\n",
    "**Preprocess the Data:**\n",
    "We need to perform some preprocessing to reshape the data into the expected format for collaborative filtering.\n",
    "- Create a user-movie `matrix Y` from ratings.csv, where `Y[i, j]` is the rating by user j for movie i. If a movie hasn't been rated by a user, fill it with 0.\n",
    "- Create a `matrix R` from ratings.csv, where `R[i, j]` is 1 if movie i has been rated by user j, and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fc6a5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "def load_movielens_data(movies_path, ratings_path):\n",
    "    movies = pd.read_csv(movies_path)\n",
    "    ratings = pd.read_csv(ratings_path)\n",
    "    \n",
    "    Y = ratings.pivot(index='movieId', columns='userId', values='rating').fillna(0).values\n",
    "    R = (Y > 0).astype(int)\n",
    "    \n",
    "    return Y, R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "529effb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(num_movies, num_users, num_features):\n",
    "    X = np.random.randn(num_movies, num_features) * 0.01\n",
    "    W = np.random.randn(num_users, num_features) * 0.01\n",
    "    b = np.zeros((1, num_users))\n",
    "    \n",
    "    return X, W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "420adb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y, R = load_movielens_data('../data/movies.csv', '../data/ratings.csv')\n",
    "num_movies, num_users = Y.shape\n",
    "num_features = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5ee59cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (Y[(Y > 0)] >= 0.5).all() and (Y[(Y > 0)] <= 5).all(), \"Ratings outside the 0.5-5 range found!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e84bdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, W, b = initialize_parameters(num_movies, num_users, num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3044a493",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6277a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y (9724, 610) R (9724, 610)\n",
      "X (9724, 10)\n",
      "W (610, 10)\n",
      "b (1, 610)\n"
     ]
    }
   ],
   "source": [
    "print(\"Y\", Y.shape, \"R\", R.shape)\n",
    "print(\"X\", X.shape)\n",
    "print(\"W\", W.shape)\n",
    "print(\"b\", b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a4b4320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R[0][0] : 1\n",
      "Y[0][0] : 4.0\n",
      "--------------------\n",
      "R[0][1] : 0\n",
      "Y[0][1] : 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"R[0][0] :\", R[0][0])    # equal to 1 if user at index 0 rated movie at index 0 \n",
    "print(\"Y[0][0] :\", Y[0][0])    # if R[0][0] == 1, this rating should be > 0\n",
    "\n",
    "print('-'*20)\n",
    "print(\"R[0][1] :\", R[0][1])    # equal to 0 if user at index 1 has not rated movie at index 0\n",
    "print(\"Y[0][1] :\", Y[0][1])    # movie rating is 0 since it is not rated by that user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa4d91d",
   "metadata": {},
   "source": [
    "## Collaborative Filtering Learning Algorithm\n",
    "The collaborative filtering algorithm in the setting of movie recommendations considers a set of $n$-dimensional parameter vectors $\\mathbf{x}^{(0)},...,\\mathbf{x}^{(n_m-1)}$, $\\mathbf{w}^{(0)},...,\\mathbf{w}^{(n_u-1)}$ and $b^{(0)},...,b^{(n_u-1)}$, where the model predicts the rating for movie $i$ by user $j$ as $y^{(i,j)} = \\mathbf{w}^{(j)}\\cdot \\mathbf{x}^{(i)} + b^{(j)}$ . Given a dataset that consists of a set of ratings produced by some users on some movies, we wish to learn the parameter vectors $\\mathbf{x}^{(0)},...,\\mathbf{x}^{(n_m-1)}, \\mathbf{w}^{(0)},...,\\mathbf{w}^{(n_u-1)}$  and $b^{(0)},...,b^{(n_u-1)}$ that produce the best fit (minimizes the squared error)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913e4b31",
   "metadata": {},
   "source": [
    "### 4.1 Collaborative filtering cost function\n",
    "\n",
    "To understand how the cost function is derived, the theory is detailed [here.](https://github.com/ali-izhar/machine-learning/tree/main/Theory/Recommender/Collaborative_Filtering)\n",
    "\n",
    "The collaborative filtering cost function is given by\n",
    "$$J({\\mathbf{x}^{(0)},...,\\mathbf{x}^{(n_m-1)},\\mathbf{w}^{(0)},b^{(0)},...,\\mathbf{w}^{(n_u-1)},b^{(n_u-1)}})= \\left[ \\frac{1}{2}\\sum_{(i,j):r(i,j)=1}(\\mathbf{w}^{(j)} \\cdot \\mathbf{x}^{(i)} + b^{(j)} - y^{(i,j)})^2 \\right]\n",
    "+ \\underbrace{\\left[\n",
    "\\frac{\\lambda}{2}\n",
    "\\sum_{j=0}^{n_u-1}\\sum_{k=0}^{n-1}(\\mathbf{w}^{(j)}_k)^2\n",
    "+ \\frac{\\lambda}{2}\\sum_{i=0}^{n_m-1}\\sum_{k=0}^{n-1}(\\mathbf{x}_k^{(i)})^2\n",
    "\\right]}_{regularization}\n",
    "\\tag{1}$$\n",
    "\n",
    "The first summation in (1) is \"for all $i$, $j$ where $r(i,j)$ equals $1$\" and could be written:\n",
    "\n",
    "$$\n",
    "= \\left[ \\frac{1}{2}\\sum_{j=0}^{n_u-1} \\sum_{i=0}^{n_m-1}r(i,j)*(\\mathbf{w}^{(j)} \\cdot \\mathbf{x}^{(i)} + b^{(j)} - y^{(i,j)})^2 \\right]\n",
    "+\\text{regularization}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ff245b",
   "metadata": {},
   "source": [
    "The below implementation is vectorized for speed. However, a simple `for loop` implementation is given here:\n",
    "\n",
    "```python\n",
    "def collaborative_filtering_cost(X, W, b, Y, R, lambda_):\n",
    "    nm, nu = Y.shape\n",
    "    J = 0\n",
    "    for i in range(nm):\n",
    "        for j in range(nu):\n",
    "            if R[i, j] == 1:\n",
    "                J += (np.dot(W[j, :], X[i, :]) + b[0, j] - Y[i, j]) ** 2\n",
    "    \n",
    "    J /= 2\n",
    "    reg_term = (lambda_ / 2) * (np.sum(W**2) + np.sum(X**2))\n",
    "    J += reg_term\n",
    "    \n",
    "    return J\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7519e20",
   "metadata": {},
   "source": [
    "In the code below, we're using the `reduce_sum` function from the tensorflow library. <i>\"It computes the sum of elements across dimensions of a tensor.\"</i> Read more on how to sum across different dimensions [here](https://www.tensorflow.org/api_docs/python/tf/math/reduce_sum).\n",
    "\n",
    "```python \n",
    "# x has a shape of (2, 3) (two rows and three columns):\n",
    "x = tf.constant([[1, 1, 1], [1, 1, 1]])\n",
    "x.numpy()\n",
    "array([[1, 1, 1],\n",
    "       [1, 1, 1]], dtype=int32)\n",
    "\n",
    "# sum all the elements\n",
    "# 1 + 1 + 1 + 1 + 1 + 1 = 6\n",
    "tf.reduce_sum(x).numpy()\n",
    "6\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "015d6fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collaborative_filtering_cost(X, W, b, Y, R, lambda_):\n",
    "    \"\"\"\n",
    "    Returns the cost for the collaborative-based filtering\n",
    "    Vectorized for speed. Uses tensorflow operations to be compatible with custom training loop.\n",
    "    Args:\n",
    "      X (ndarray (num_movies,num_features)): matrix of item features\n",
    "      W (ndarray (num_users,num_features)) : matrix of user parameters\n",
    "      b (ndarray (1, num_users)            : vector of user parameters\n",
    "      Y (ndarray (num_movies,num_users)    : matrix of user ratings of movies\n",
    "      R (ndarray (num_movies,num_users)    : matrix, where R(i, j) = 1 if the i-th movies was rated by the j-th user\n",
    "      lambda_ (float): regularization parameter\n",
    "    Returns:\n",
    "      J (float) : Cost\n",
    "    \"\"\"\n",
    "    \n",
    "    # multiplication with R automatically filters out the 0 entries\n",
    "    j = (tf.linalg.matmul(X, tf.transpose(W)) + b - Y)*R\n",
    "    J = 0.5 * tf.reduce_sum(j**2) + (lambda_/2) * (tf.reduce_sum(X**2) + tf.reduce_sum(W**2))\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfab41c",
   "metadata": {},
   "source": [
    "## Learning Movie Recommendations\n",
    "\n",
    "First, we need a list of movies. Next, we'll generate random ratings for these movies and add them to our dataset. After that, we'll normalize the ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17bcabfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_movie_list_pd():\n",
    "    \"\"\" \n",
    "    Returns a list of movies and a dataframe with the corresponding indices.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv('../data/movies.csv', usecols=['movieId', 'title'], index_col='movieId')\n",
    "    mlist = df[\"title\"].to_list()\n",
    "    return mlist, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99f9b458",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_movies_list, all_movies_df = load_movie_list_pd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "028e584a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New user ratings:\n",
      "\n",
      "Rated 5.0 for Shrek (2001)\n",
      "Rated 5.0 for Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)\n",
      "Rated 2.0 for Amelie (Fabuleux destin d'Amélie Poulain, Le) (2001)\n",
      "Rated 5.0 for Harry Potter and the Chamber of Secrets (2002)\n",
      "Rated 5.0 for Pirates of the Caribbean: The Curse of the Black Pearl (2003)\n",
      "Rated 5.0 for Lord of the Rings: The Return of the King, The (2003)\n",
      "Rated 3.0 for Eternal Sunshine of the Spotless Mind (2004)\n",
      "Rated 5.0 for Incredibles, The (2004)\n",
      "Rated 2.0 for Persuasion (2007)\n",
      "Rated 5.0 for Toy Story 3 (2010)\n",
      "Rated 3.0 for Inception (2010)\n",
      "Rated 1.0 for Louis Theroux: Law & Disorder (2008)\n",
      "Rated 1.0 for Nothing to Declare (Rien à déclarer) (2010)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "78499,Toy Story 3 (2010)\n",
    "74508,Persuasion (2007)\n",
    "7153,Lord of the Rings: The Return of the King, The (2003)\n",
    "4306,Shrek (2001)\n",
    "79132,Inception (2010)\n",
    "8961,Incredibles, The (2004)\n",
    "4973,Amelie (Fabuleux destin d'Amélie Poulain, Le) (2001)\n",
    "4896,Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)\n",
    "5816,Harry Potter and the Chamber of Secrets (2002)\n",
    "7361,Eternal Sunshine of the Spotless Mind (2004)\n",
    "86668,Louis Theroux: Law & Disorder (2008)\n",
    "86922,Nothing to Declare (Rien à déclarer) (2010)\n",
    "6539,Pirates of the Caribbean: The Curse of the Black Pearl (2003)\n",
    "\"\"\"\n",
    "\n",
    "# Initialize the ratings with zeros for all movies\n",
    "my_ratings = np.zeros((num_movies, 1))\n",
    "\n",
    "movie_ids = [78499, 74508, 7153, 4306, 79132, 8961, 4973, 4896, 5816, 7361, 86668, 86922, 6539]\n",
    "ratings = [5, 2, 5, 5, 3, 5, 2, 5, 5, 3, 1, 1, 5]\n",
    "\n",
    "for i in range(len(movie_ids)):\n",
    "    if movie_ids[i] in all_movies_df.index:\n",
    "        index_loc = all_movies_df.index.get_loc(movie_ids[i])\n",
    "        my_ratings[index_loc] = ratings[i]\n",
    "    else:\n",
    "        print(f\"Warning: Movie ID {movie_ids[i]} not found in the dataset.\")\n",
    "\n",
    "my_rated = [i for i in range(len(my_ratings)) if my_ratings[i] > 0]\n",
    "        \n",
    "print('\\nNew user ratings:\\n')\n",
    "for i in range(len(my_ratings)):\n",
    "    if my_ratings[i] > 0:\n",
    "        movie_id = all_movies_df.iloc[i].name\n",
    "        print(f'Rated {my_ratings[i][0]} for {all_movies_df.loc[movie_id, \"title\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fe123c",
   "metadata": {},
   "source": [
    "Now, let's add these reviews to $Y$ and $R$ and normalize the ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a810ef",
   "metadata": {},
   "source": [
    "## Normalize Ratings\n",
    "Normalize the ratings to ensure that the optimization procedure works better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2f05f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_ratings(Y, R):\n",
    "    \"\"\"\n",
    "    Preprocess data by subtracting mean rating for every movie (every row). Only include real ratings R(i,j)=1. \n",
    "    Returns the mean rating for every movie.\n",
    "    \n",
    "    - Y*R: Multiplies the ratings matrix Y by the matrix R which indicates whether a movie was rated (R(i,j) = 1) \n",
    "        or not (R(i,j) = 0). This has the effect of \"zeroing-out\" unrated movies, making them not contribute to the sum.\n",
    "    - np.sum(Y*R, axis=1): Sum the ratings for each movie across all users. A movie is a row in the dataset, therefore,\n",
    "        add along all cols (axis=1) for each row.\n",
    "    - np.sum(R, axis=1): Count the number of ratings for each movie.\n",
    "    - The division computes the average (mean) rating for each movie.\n",
    "    - reshape(-1,1): Reshapes the resulting array into a column vector.\n",
    "    - 1e-12: A small number is added to the denominator to prevent division by zero.\n",
    "    \"\"\"\n",
    "    \n",
    "    Ymean = (np.sum(Y*R, axis=1)/(np.sum(R, axis=1)+1e-12)).reshape(-1,1)\n",
    "    Ynorm = Y - np.multiply(Ymean, R) \n",
    "    return (Ynorm, Ymean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "040deebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add normalized ratings \n",
    "Y = np.hstack((Y, my_ratings))\n",
    "R = np.hstack((R, (my_ratings > 0).astype(int)))\n",
    "  \n",
    "# Normalize all ratings\n",
    "Ynorm, Ymean = normalize_ratings(Y, R)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5100ab4",
   "metadata": {},
   "source": [
    "## Training the Recommender System\n",
    "\n",
    "With our data in place, we can now train the recommender system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9878e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_recommender(X, W, b, Ynorm, R, learning_rate, num_epochs, lambda_):\n",
    "    optimizer = tf.optimizers.Adam(learning_rate)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        with tf.GradientTape() as tape:\n",
    "            J = collaborative_filtering_cost(X, W, b, Ynorm, R, lambda_)\n",
    "            \n",
    "        # Calculate Gradients\n",
    "        grads = tape.gradient(J, [X, W, b])\n",
    "        \n",
    "        # Update Parameters using Gradient Descent\n",
    "        optimizer.apply_gradients(zip(grads, [X, W, b]))\n",
    "        \n",
    "        if epoch % 20 == 0:\n",
    "            print(f'Epoch: {epoch}, Loss: {J:0.2f}')\n",
    "\n",
    "    return X, W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da378402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-initialize varialbes since we added new ratings\n",
    "num_movies, num_users = Y.shape\n",
    "num_features = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc509637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "lambda_ = 1\n",
    "learning_rate = 1e-1\n",
    "num_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5999f409",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234)\n",
    "\n",
    "# Set Initial Parameters (W, X), use tf.Variable to track these variables\n",
    "X = tf.Variable(tf.random.normal((num_movies, num_features), dtype=tf.float64), name='X') \n",
    "\n",
    "W = tf.Variable(tf.random.normal((num_users, num_features), dtype=tf.float64), name='W')\n",
    "\n",
    "b = tf.Variable(tf.random.normal((1, num_users), dtype=tf.float64), name='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a2f0c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 5574885.47\n",
      "Epoch: 20, Loss: 281720.28\n",
      "Epoch: 40, Loss: 109026.97\n",
      "Epoch: 60, Loss: 53495.20\n",
      "Epoch: 80, Loss: 30611.95\n",
      "Epoch: 100, Loss: 19556.34\n",
      "Epoch: 120, Loss: 13611.08\n",
      "Epoch: 140, Loss: 10195.54\n",
      "Epoch: 160, Loss: 8143.67\n",
      "Epoch: 180, Loss: 6867.99\n"
     ]
    }
   ],
   "source": [
    "X_trained, W_trained, b_trained = train_recommender(X, W, b, Ynorm, R, learning_rate, num_epochs, lambda_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18dd4d7",
   "metadata": {},
   "source": [
    "## Movie Recommendations\n",
    "\n",
    "Let's see the movie recommendations for us based on our given ratings.\n",
    "\n",
    "To predict the rating of movie $i$ for user $j$, we compute $\\mathbf{w}^{(j)} \\cdot \\mathbf{x}^{(i)} + b^{(j)}$. This can be computed for all ratings using matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c360077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_movies(X, W, b, Ymean, all_movies_list, my_ratings, my_rated):\n",
    "    \"\"\"\n",
    "    Provide personalized movie recommendations and compare original ratings to predictions.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Make a prediction using trained weights and biases\n",
    "    p = np.matmul(X.numpy(), np.transpose(W.numpy())) + b.numpy()\n",
    "    \n",
    "    # Restore the mean\n",
    "    pm = p + Ymean\n",
    "    my_predictions = pm[:, 0]\n",
    "\n",
    "    # Rescale predictions to be within 0.5 and 5\n",
    "    min_pred = np.min(my_predictions)\n",
    "    max_pred = np.max(my_predictions)\n",
    "    \n",
    "    my_predictions = 0.5 + (my_predictions - min_pred) * (4.5 / (max_pred - min_pred))\n",
    "\n",
    "    # Sort predictions\n",
    "    ix = tf.argsort(my_predictions, direction='DESCENDING')\n",
    "\n",
    "    for i in range(17):\n",
    "        j = ix[i]\n",
    "        if j not in my_rated:\n",
    "            print(f'Predicting rating {my_predictions[j]:0.2f} for movie {all_movies_list[j]}')\n",
    "\n",
    "    print('\\n\\nOriginal vs Predicted ratings:\\n')\n",
    "    for i in range(len(my_ratings)):\n",
    "        if my_ratings[i] > 0:\n",
    "            print(f'Original {my_ratings[i]}, Predicted {my_predictions[i]:0.2f} for {all_movies_list[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88e5b07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting rating 5.00 for movie Taxi Driver (1976)\n",
      "Predicting rating 4.92 for movie Léon: The Professional (a.k.a. The Professional) (Léon) (1994)\n",
      "Predicting rating 4.90 for movie 2001: A Space Odyssey (1968)\n",
      "Predicting rating 4.88 for movie Mystery Science Theater 3000: The Movie (1996)\n",
      "Predicting rating 4.86 for movie All of Me (1984)\n",
      "Predicting rating 4.78 for movie Citizen Ruth (1996)\n",
      "Predicting rating 4.70 for movie Jesus Camp (2006)\n",
      "Predicting rating 4.65 for movie Hood of Horror (2006)\n",
      "Predicting rating 4.65 for movie Mortal Kombat: Annihilation (1997)\n",
      "Predicting rating 4.65 for movie Interstate 60 (2002)\n",
      "Predicting rating 4.62 for movie Down by Law (1986)\n",
      "Predicting rating 4.52 for movie Legends of the Fall (1994)\n",
      "Predicting rating 4.46 for movie Cooler, The (2003)\n",
      "Predicting rating 4.43 for movie For Richer or Poorer (1997)\n",
      "Predicting rating 4.42 for movie Soul Plane (2004)\n",
      "Predicting rating 4.42 for movie Trapped (2002)\n",
      "Predicting rating 4.35 for movie Ender's Game (2013)\n",
      "\n",
      "\n",
      "Original vs Predicted ratings:\n",
      "\n",
      "Original [5.], Predicted 3.45 for Shrek (2001)\n",
      "Original [5.], Predicted 2.50 for Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)\n",
      "Original [2.], Predicted 2.67 for Amelie (Fabuleux destin d'Amélie Poulain, Le) (2001)\n",
      "Original [5.], Predicted 3.70 for Harry Potter and the Chamber of Secrets (2002)\n",
      "Original [5.], Predicted 3.04 for Pirates of the Caribbean: The Curse of the Black Pearl (2003)\n",
      "Original [5.], Predicted 2.93 for Lord of the Rings: The Return of the King, The (2003)\n",
      "Original [3.], Predicted 2.34 for Eternal Sunshine of the Spotless Mind (2004)\n",
      "Original [5.], Predicted 2.52 for Incredibles, The (2004)\n",
      "Original [2.], Predicted 2.36 for Persuasion (2007)\n",
      "Original [5.], Predicted 2.29 for Toy Story 3 (2010)\n",
      "Original [3.], Predicted 2.33 for Inception (2010)\n",
      "Original [1.], Predicted 1.55 for Louis Theroux: Law & Disorder (2008)\n",
      "Original [1.], Predicted 1.95 for Nothing to Declare (Rien à déclarer) (2010)\n"
     ]
    }
   ],
   "source": [
    "recommend_movies(X_trained, W_trained, b_trained, Ymean, all_movies_list, my_ratings, my_rated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c729583",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The model uses collaborative filtering to provide personalized movie recommendations. It can be further enhanced using more sophisticated architectures, but the core idea remains the same: to predict user ratings based on historical data and recommend items accordingly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
