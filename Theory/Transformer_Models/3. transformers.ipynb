{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "875403eb",
   "metadata": {},
   "source": [
    "## 1 - Skip Connection\n",
    "<hr>\n",
    "\n",
    "We covered in detail the attention mechanism in the last two notebooks. Attention is the most fundamental part of what transformers do. In this notebook, we put it all together to create a transformer architecture.\n",
    "\n",
    "One piece we haven't explained yet are **skip connections.** These occur around the Multi-Head Attention blocks, and around the element wise Feed Forward blocks in the blocks labeled \"Add and Norm\". In skip connections, a copy of the input is added to the output of a set of calculations. The inputs to the attention block are added back in to its output. The inputs to the element-wise feed forward block are added to its outputs.\n",
    "\n",
    "<img src=\"images/architecture_add_norm.png\" width=450>\n",
    "\n",
    "Skip connections serve two purposes:\n",
    "\n",
    "The first is that they help keep the gradient smooth, which is a big help for backpropagation. Attention is a filter, which means that when it's working correctly it will block most of what tries to pass through it. The result of this is that small changes in a lot of the inputs may not produce much change in the outputs if they happen to fall into channels that are blocked. This produces dead spots in the gradient where it is flat, but still nowhere near the bottom of a valley. These saddle points and ridges are a big tripping point for backpropagation. Skip connections help to smooth these out. In the case of attention, even if all of the weights were zero and all the inputs were blocked, a skip connection would add a copy of the inputs to the results and ensure that small changes in any of the inputs will still have noticeable changes in the result. This keeps gradient descent from getting stuck far away from a good solution.\n",
    "\n",
    "Skip connections have become popular because of how they improve performance since the days of the ResNet image classifier. They are now a standard feature in neural network architectures. Visually, we can see the effect that skip connections have by comparing networks with and without them. The figure below from [this paper](https://arxiv.org/abs/1712.09913) shows a ResNet with and without skip connections. The slopes of the loss function hills are are much more moderate and uniform when skip connections are used.\n",
    "\n",
    "<img src=\"images/skip_connection_gradients.png\" width=600>\n",
    "\n",
    "The second purpose of skip connections is specific to transformers — preserving the original input sequence. Even with a lot of attention heads, there’s no guarantee that a word will attend to its own position. It’s possible for the attention filter to forget entirely about the most recent word in favor of watching all of the earlier words that might be relevant. A skip connection takes the original word and manually adds it back into the signal, so that there’s no way it can be dropped or forgotten. This source of robustness may be one of the reasons for transformers' good behavior in so many varied sequence completion tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5811e3",
   "metadata": {},
   "source": [
    "## 2 - Layer Normalization\n",
    "<hr>\n",
    "\n",
    "Normalization is a step that pairs well with skip connections. There's no reason they necessarily have to go together, but they both do their best work when placed after a group of calculations, like attention or a feed forward neural network.\n",
    "\n",
    "The short version of layer normalization is that the values of the matrix are shifted to have a mean of zero and scaled to have a standard deviation of one.\n",
    "\n",
    "<img src=\"images/normalization.png\" width=400>\n",
    "\n",
    "The longer version is that in systems like transformers, where there are a lot of moving pieces and some of them are something other than matrix multiplications (such as softmax operators or rectified linear units), it matters how big values are and how they're balanced between positive and negative. If everything is linear, you can double all your inputs, and your outputs will be twice as big, and everything will work just fine. Not so with neural networks. They are inherently nonlinear, which makes them very expressive but also sensitive to signals' magnitudes and distributions. Normalization is a technique that has proven useful in maintaining a consistent distribution of signal values each step of the way throughout many-layered neural networks. It encourages convergence of parameter values and usually results in much better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3124ca25",
   "metadata": {},
   "source": [
    "## 3 - Multiple Layers\n",
    "<hr>\n",
    "\n",
    "At the beginning, the weights are all chosen randomly, most of them are close to zero, and the few that aren't probably aren't the ones we need. It's a long way from where it needs to be for our model to perform well.\n",
    "\n",
    "Stochastic gradient descent through backpropagation can do some pretty amazing things, but it relies a lot on luck. If there is just one way to get to the right answer, just one combination of weights necessary for the network to work well, then it's unlikely that it will find its way. But if there are lots of paths to a good solution, chances are much better that the model will get there.\n",
    "\n",
    "Having a single attention layer (just one multi-head attention block and one feed forward block) only allows for one path to a good set of transformer parameters. Every element of every matrix needs to find its way to the right value to make things work well. It is fragile and brittle, likely to get stuck in a far-from-ideal solution unless the initial guesses for the parameters are very very lucky.\n",
    "\n",
    "The way transformers sidestep this problem is by having multiple attention layers, each using the output of the previous one as its input. The use of skip connections make the overal pipeline robust to individual attention blocks failing or giving wonky results. Having multiples means that there are others waiting to take up the slack. If one should go off the rails, or in any way fail to live up to its potential, there will be another downstream that has another chance to close the gap or fix the error. The paper showed that more layers resulted in better performance, although the improvement became marginal after 6.\n",
    "\n",
    "Another way to think about multiple layers is as a conveyor belt assembly line. Each attention block and feedforward block has the chance to pull inputs off the line, calculate useful attention matrices and make next word predictions. Whatever results they produce, useful or not, get added back onto the conveyer, and passed to the next layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfac9f1a",
   "metadata": {},
   "source": [
    "## 4 - Cross-attention\n",
    "<hr>\n",
    "\n",
    "The final step in getting the full transformer up and running is the connection between the encoder and decoder stacks, the cross attention block.\n",
    "\n",
    "Cross-attention works just like self-attention with the exception that the key matrix $K$ and value matrix $V$ are based on the output of the final encoder layer, rather than the output of the previous decoder layer. The query matrix $Q$ is still calculated from the results of the previous decoder layer. This is the channel by which information from the source sequence makes its way into the target sequence and steers its creation in the right direction. It's interesting to note that the same embedded source sequence is provided to every layer of the decoder, supporting the notion that successive layers provide redundancy and are all cooperating to perform the same task.\n",
    "\n",
    "<img src=\"images/architecture_cross_attention.png\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaa9a42",
   "metadata": {},
   "source": [
    "### References\n",
    "The contents of this notebook are based on the following article:\n",
    "\n",
    "https://e2eml.school/transformers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data Mining (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
