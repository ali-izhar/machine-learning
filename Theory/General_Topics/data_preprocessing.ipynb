{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c34761b0",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "Data preprocessing is the process of cleaning, transforming, and organizing a dataset in order to prepare it for data analysis and modeling. It aims to improve the quality, integrity, and reliability of the data, and addresses issues such as missing values, noisy data, outliers, and incompatible data formats.\n",
    "\n",
    "\"Garbage in, garbage out\" is a known phrase in data science, which expresses the idea that the quality of the results of a model is determined by the quality of its inputs. The more informative and less noisy the data is, the better the model will be able to learn the underlying patterns or relationships in the data and generalize to new unseen data.\n",
    "\n",
    "## Data Preprocessing Tasks\n",
    "The main tasks involved in data preprocessing are:\n",
    "- Data cleaning\n",
    "- Handling missing data\n",
    "- Encoding categorical data\n",
    "- Detecting and handling outliers\n",
    "- Handling skewed data\n",
    "- Discretization\n",
    "- Scaling and normalization\n",
    "\n",
    "Feature selection and extraction are considered separate steps from data preprocessing, although there can be some overlap between them.\n",
    "\n",
    "The main modules in Scikit-Learn that are used for data preprocessing are:\n",
    "- `sklearn.preprocessing` provides various transformers for scaling, normalization, encoding features, and discretization.\n",
    "- `sklearn.impute` provides transformers for imputing missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed20f0e4",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "Data cleaning (or cleansing) involves correcting or removing incorrect, inaccurate, inconsistent, irrelevant, or duplicate data from the data set. These issues can arise from various sources, such as:\n",
    "\n",
    "- Data entry errors (e.g., an invalid postal code, typographical errors)\n",
    "- Out-of-range values (e.g., a negative product price)\n",
    "- Corruption in transmitting or storage of the data\n",
    "- Merging ambiguous data from different sources (e.g., the same customer was stored in two systems with two different addresses)\n",
    "- Using inconsistent formats for dates, phone numbers, names of states, etc.\n",
    "- Using inconsistent unit measures (e.g., using both centimeters and feet to measure length)\n",
    "- Including features that are irrelevant to the analysis, such as user id\n",
    "\n",
    "Data cleaning is performed using a combination of manual correction operations with automatic processing tools, and often requires domain expertise in order to identify and resolve the inaccuracies and inconsistencies in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76c024c",
   "metadata": {},
   "source": [
    "## Handling Missing Values\n",
    "Missing data is one of the most common issues in real-world data sets. It can occur due to various reasons, such as data entry errors, null values in a database, private information, etc. In Python, missing values are typically represented by `NaN` (Not a Number) or None values.\n",
    "\n",
    "Many machine learning algorithms cannot deal with missing values (exceptions include KNN, Naive Bayes, and decision trees), thus this issue needs to be resolved during the data preparation phase.\n",
    "\n",
    "Common approaches for dealing with missing data include:\n",
    "- Remove the samples with missing values. This option is recommended only if there is a small number of such samples.\n",
    "- Remove features that have a high percentage of missing values.\n",
    "- Impute the missing values, i.e., replace them with some appropriate fill value, such as the mean or median of the corresponding feature.\n",
    "\n",
    "Scikit-Learn provides three types of imputers:\n",
    "\n",
    "1. `SimpleImputer` imputes the missing values using the statistics (e.g., mean, median, or mode) of the feature with the missing values or using a constant value. Its important parameters are:\n",
    "- `missing_values:` which values are considered to be missing values (defaults to `np.nan`).\n",
    "- `strategy:` the statistic to use for the imputation. The options are 'mean' (the default), 'median', 'most_frequent' and 'constant'. For categorical features, only the options 'most_frequent' and 'constant' can be used.\n",
    "- `fill_value:` which constant to use for replacing the missing values (when the chosen strategy is 'constant')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b21b0e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[nan, 5, nan], [2, 4, 10], [3, nan, 5]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# imputing missing values with the mean of each feature\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "X = [[np.nan, 5, np.nan], [2, 4, 10], [3, np.nan, 5]]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ba9c68b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.5,  5. ,  7.5],\n",
       "       [ 2. ,  4. , 10. ],\n",
       "       [ 3. ,  4.5,  5. ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b182e2",
   "metadata": {},
   "source": [
    "2. `IterativeImputer` models each feature with missing values as a function of the other features, in a round-robin fashion. In each iteration, one of the features with missing values is designated as the output $y$, and the other features are treated as the inputs $X$. Then, a regression model is trained on $(X, y)$, and used to predict the missing values of $y$. This process is repeated for `max_iter` imputation rounds.\n",
    "\n",
    "Important parameters of this transformer:\n",
    "\n",
    "- `estimator:` the estimator to use for the imputation (the default is BayesianRidge).\n",
    "- `max_iter:` maximum number of imputation rounds (defaults to 10).\n",
    "- `initial_strategy:` which strategy to use to initialize the missing values (same as the strategy parameter in SimpleImputer).\n",
    "- `imputation_order:` the order in which the features will be imputed. Defaults to 'ascending', i.e., from features with the fewest missing values to the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7844e5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2], [2, 4], [4, 8], [nan, 3], [5, nan]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "imputer = IterativeImputer(max_iter=10)\n",
    "\n",
    "X = [[1, 2], [2, 4], [4, 8], [np.nan, 3], [5, np.nan]]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d03b815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  2.        ],\n",
       "       [ 2.        ,  4.        ],\n",
       "       [ 4.        ,  8.        ],\n",
       "       [ 1.50000846,  3.        ],\n",
       "       [ 5.        , 10.00000145]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822702e0",
   "metadata": {},
   "source": [
    "We can see that the imputer has learned that the second feature is equal to twice of the first one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4758abf5",
   "metadata": {},
   "source": [
    "3. `KNNImputer` imputes the missing values by using the mean value of the k-nearest neighbors that have a value for the missing feature.\n",
    "\n",
    "Important parameters of this transformer:\n",
    "\n",
    "- `n_neighbors:` the number of neighbors to use for the imputation (defaults to 5)\n",
    "- `weights:` whether to weight the neighbors uniformly (the default) or by the inverse of their distance.\n",
    "- `metric:` the metric to use for computing the distances. Possible values are 'nan_euclidean' (an Euclidean distance metric that supports missing values) or a custom function.\n",
    "\n",
    "The following example replaces the missing values with the mean feature value of the two nearest neighbors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2d1c79a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, nan], [3, 2, 3], [6, nan, 5], [7, 8, 10]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=2)\n",
    "\n",
    "X = [[1, 2, np.nan], [3, 2, 3], [6, np.nan, 5], [7, 8, 10]]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "350b6ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.,  4.],\n",
       "       [ 3.,  2.,  3.],\n",
       "       [ 6.,  5.,  5.],\n",
       "       [ 7.,  8., 10.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47aa4ba7",
   "metadata": {},
   "source": [
    "## Encoding Categorical Data\n",
    "Most machine learning models cannot handle categorical features directly, thus these features need to be converted into a numerical format. There are three main approaches for encoding categorical data:\n",
    "\n",
    "1. **Ordinal encoding** assigns a unique integer value to each category based on the order or ranking of the categories. For example, a categorical feature of `IncomeLevel` with three categories: `Low, Medium` and `High,` could be encoded as 0, 1, and 2, respectively.\n",
    "2. **One-hot encoding** converts a categorical variable with $n$ categories into $n$ binary features, with one of them 1, and all the others 0. For example, one-hot encoding of the `IncomeLevel` variable would create three binary features: `LowIncome, MediumIncome,` and `HighIncome.` For a sample that belongs to the `HighIncome` category, the `HighIncome` feature would be 1, and the other features would be 0.\n",
    "3. **Hash encoding** applies a hash function to the categories and converts them into a fixed number of dimensions. It is more memory efficient than one-hot encoding, but different categories may be mapped to the same hash value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a83f7115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['LowIncome', 'BA'], ['HighIncome', 'PhD'], ['MediumIncome', 'BA']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "encoder = OrdinalEncoder()\n",
    "\n",
    "X = [['LowIncome', 'BA'], ['HighIncome', 'PhD'], ['MediumIncome', 'BA']]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4be73a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.],\n",
       "       [2., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c4d3d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['LowIncome', 'BA'], ['HighIncome', 'PhD'], ['MediumIncome', 'BA']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "X = [['LowIncome', 'BA'], ['HighIncome', 'PhD'], ['MediumIncome', 'BA']]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa9f4d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 1., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbb1cb4",
   "metadata": {},
   "source": [
    "## Detecting and Handling Outliers\n",
    "Outliers are data points that significantly deviate from the majority of the data. They can be caused by data entry errors or measurement errors, but they can also represent real anomalous observations.\n",
    "\n",
    "There are various methods to detect outliers, such as:\n",
    "\n",
    "1. Using statistical measures such as z-score, which represents the number of standard deviations away from the mean:\n",
    "\n",
    "$$z = \\frac{x - \\mu}{\\sigma}$$\n",
    "\n",
    "2. Using plots such as percentile or box-plot. A box-plot visually displays the quartiles and any data points outside a specified range (e.g., 1.5 times the IQR above the upper quartile or below the lower quartile) are considered outliers.\n",
    "\n",
    "<div style=\"align:center\">\n",
    "    <img src=\"media/boxplot.png\" width=400>\n",
    "</div>\n",
    "\n",
    "3. Density-based clustering methods, such as DBSCAN, can identify outliers based on the density of the data points.\n",
    "4. Isolation forest is an ensemble-based approach for anomaly detection.\n",
    "\n",
    "There are also different ways to handle outliers, depending on the nature and extent of the outliers:\n",
    "\n",
    "- Remove the outliers. This is the simplest approach, but it should be done judiciously, as it can potentially lead to information loss.\n",
    "- Treat the outliers as missing values and then use one of the aforementioned imputation methods to replace them.\n",
    "- Capping sets a predefined threshold for extreme values. Any data point that exceeds the threshold is replaced with the threshold value.\n",
    "- Winsorization sets all the outliers to a specified percentile of the data. For example, a 90% winsorization replaces all the data points above the 95th percentile with the 95th percentile, and all the points below the 5th percentile with the 5th percentile. This approach limits the impact of outliers without completely removing them.\n",
    "- Use discretization to group the data points into bins, and assign the outliers to a separate bin or to the nearest bin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3dacde",
   "metadata": {},
   "source": [
    "## Handling Skewed Data\n",
    "Skewed data is data that is not symmetrically distributed around the mean and has a long tail toward one direction. Skewness can impact the performance of some machine learning models, which assume a symmetric or even normal distribution of the data (e.g., Gaussian Naive Bayes assumes that the features are normally distributed).\n",
    "\n",
    "There are several methods to deal with skewed data:\n",
    "\n",
    "1. Logarithmic transformation: taking the logarithm can help reduce right skewness since it compresses larger values while maintaining the order of the data.\n",
    "2. Exponential transformation: taking the reciprocal of the data $(y = x^{-1})$ can help reduce left skewness and make the distribution more symmetric.\n",
    "3. Winsorization: as in outlier handling, winsorization can handle skewness by replacing extreme values with values at a specified percentile.\n",
    "4. Power transformations involve raising the data to a power, which is determined through maximum likelihood estimation. They can transform the data to a more symmetric and approximately normal distribution.\n",
    "\n",
    "- Box-Cox transform, which works only with strictly positive values:\n",
    "\n",
    "$$ x' = \\begin{cases}\n",
    "    \\frac{x^{\\lambda} - 1}{\\lambda} & \\lambda \\neq 0 \\\\\n",
    "    \\ln{(x)} & \\lambda =0 \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "- Yeo-Johnson transform, which works with any real value:\n",
    "\n",
    "$$ x'  \\begin{cases}\n",
    "    \\frac{(x+1)^{\\lambda} - 1}{\\lambda} & \\lambda \\neq 0, x \\ge 0 \\\\\n",
    "    \\ln{(x+1)} & \\lambda = 0, x \\ge 0 \\\\\n",
    "    - \\frac{(x+1)^{2-\\lambda} - 1}{2-\\lambda} & \\lambda \\neq 2, x \\lt 0 \\\\\n",
    "    - \\ln{(-x+1)} & \\lambda = 2, x \\lt 0 \\\\\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d2930d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([80., 96., 72., 51., 43., 22., 24., 25., 17.,  8.,  9.,  4.,  5.,\n",
       "         1.,  7.,  5.,  0.,  3.,  3.,  3.,  0.,  3.,  4.,  4.,  0.,  1.,\n",
       "         1.,  0.,  0.,  1.,  0.,  1.,  3.,  1.,  0.,  0.,  1.,  1.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.]),\n",
       " array([ 0.06249975,  0.3577228 ,  0.65294586,  0.94816892,  1.24339197,\n",
       "         1.53861503,  1.83383809,  2.12906114,  2.4242842 ,  2.71950726,\n",
       "         3.01473031,  3.30995337,  3.60517643,  3.90039948,  4.19562254,\n",
       "         4.4908456 ,  4.78606865,  5.08129171,  5.37651477,  5.67173783,\n",
       "         5.96696088,  6.26218394,  6.557407  ,  6.85263005,  7.14785311,\n",
       "         7.44307617,  7.73829922,  8.03352228,  8.32874534,  8.62396839,\n",
       "         8.91919145,  9.21441451,  9.50963756,  9.80486062, 10.10008368,\n",
       "        10.39530673, 10.69052979, 10.98575285, 11.2809759 , 11.57619896,\n",
       "        11.87142202, 12.16664507, 12.46186813, 12.75709119, 13.05231424,\n",
       "        13.3475373 , 13.64276036, 13.93798341, 14.23320647, 14.52842953,\n",
       "        14.82365258]),\n",
       " <BarContainer object of 50 artists>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = np.random.RandomState(0).lognormal(size=500)\n",
    "plt.hist(X, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c408d8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2.,  2.,  1.,  0.,  2.,  2.,  3.,  3.,  1.,  4.,  8.,  6.,  9.,\n",
       "         7., 12., 13., 16., 11., 17., 24., 11., 25., 26., 17., 23., 18.,\n",
       "        22., 17., 22., 25., 13., 20., 17., 17., 15., 10., 10.,  5.,  3.,\n",
       "        10.,  3.,  6.,  6.,  6.,  1.,  2.,  4.,  2.,  0.,  1.]),\n",
       " array([-2.78605849, -2.67644406, -2.56682963, -2.4572152 , -2.34760077,\n",
       "        -2.23798634, -2.12837191, -2.01875748, -1.90914305, -1.79952861,\n",
       "        -1.68991418, -1.58029975, -1.47068532, -1.36107089, -1.25145646,\n",
       "        -1.14184203, -1.0322276 , -0.92261317, -0.81299874, -0.70338431,\n",
       "        -0.59376988, -0.48415545, -0.37454102, -0.26492659, -0.15531216,\n",
       "        -0.04569773,  0.0639167 ,  0.17353113,  0.28314556,  0.39275999,\n",
       "         0.50237442,  0.61198885,  0.72160328,  0.83121771,  0.94083215,\n",
       "         1.05044658,  1.16006101,  1.26967544,  1.37928987,  1.4889043 ,\n",
       "         1.59851873,  1.70813316,  1.81774759,  1.92736202,  2.03697645,\n",
       "         2.14659088,  2.25620531,  2.36581974,  2.47543417,  2.5850486 ,\n",
       "         2.69466303]),\n",
       " <BarContainer object of 50 artists>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "pt = PowerTransformer('box-cox')\n",
    "\n",
    "X_new = pt.fit_transform(X.reshape(-1, 1))\n",
    "plt.hist(X_new, bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c744146",
   "metadata": {},
   "source": [
    "## Discretization\n",
    "Discretization transforms a continuous-valued feature into a discrete one by partitioning the range of its values into a set of intervals or bins. The two main methods for discretization are:\n",
    "\n",
    "1. Equal width/binning: the range of the variable is divided into equal-width bins. For example, if the range of the variable is 0–20 and we want 5 bins, then each bin will cover a range of 4 units (0–4,4–8,8–12,12–16,16–20).\n",
    "2. Equal frequency: each bin contains the same number of data points.\n",
    "\n",
    "The discretized values are usually one-hot encoded. For example, if the number of bins is 5, the result of the discretization will be 5 new binary features, where each feature indicates whether the given sample belongs to the corresponding bin.\n",
    "\n",
    "Use cases for discretization:\n",
    "\n",
    "- Some machine learning algorithms cannot handle continuous values directly, such as some variants of Naive Bayes and the Apriori algorithm for association rule mining.\n",
    "- Discretization can make the model more expressive since it allows the model to find a mapping between each interval and the target label. For example, imagine that we need to predict the price of a house given its location, represented by its latitude and longitude. If we use a linear regression model, it can only find a linear correlation between the exact location of the house and its price. However, if we discretize the latitude and longitude into 10 bins each, the model can find a linear correlation between each one of the 100 areas and the price of the house.\n",
    "- Handle outliers or extreme values by placing them in their own category.\n",
    "\n",
    "The drawback of discretization is that it can lead to a loss of information, and may introduce bias if the number of bins is too small or their edges are not properly chosen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a568c557",
   "metadata": {},
   "source": [
    "## Scaling and Normalization\n",
    "Many machine learning algorithms do not perform well when the features have different scales. These include distance-based algorithms such as KNN and k-means (since the distances are dominated by features with larger ranges), and algorithms that use gradient descent for optimization, such as neural networks (as different ranges induce different step sizes for each feature).\n",
    "\n",
    "The goal of feature scaling is to bring all the features to a common scale or range. The most common approaches for feature scaling are:\n",
    "\n",
    "**Min-max scaling** scales all the features to the same range [min, max], where the typical range is [0, 1]. Mathematically, this transformation can be expressed as:\n",
    "\n",
    "$$x' = \\frac{x - x_{min}}{x_{max} - x_{min}}$$\n",
    "\n",
    "**Pros:**\n",
    "- Brings all the features to the same range.\n",
    "\n",
    "**Cons:**\n",
    "- Sensitive to outliers. Since the range of the data is determined by the minimum and the maximum, outliers can cause the scaling to compress the majority of the data into a small range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0aed328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-1, 2, 3], [0.5, 6, 10], [0, 1, 8]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X = [[-1, 2, 3], [0.5, 6, 10], [0, 1, 8]]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d120652e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.2       , 0.        ],\n",
       "       [1.        , 1.        , 1.        ],\n",
       "       [0.66666667, 0.        , 0.71428571]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff03885",
   "metadata": {},
   "source": [
    "**Standardization** (also known as z-score normalization) subtracts from each feature its mean and scales it to unit variance. The z-score of a sample $x$ is calculated as:\n",
    "\n",
    "$$x' = \\frac{x - \\mu}{\\sigma}$$\n",
    "\n",
    "where $\\mu$ is the mean of the data points and $\\sigma$ is their standard deviation.\n",
    "\n",
    "**Pros:**\n",
    "- Transforms the features to have 0 mean and unit variance, which is useful for algorithms that assume standardized features (e.g., PCA assumes that the features are centered around 0).\n",
    "\n",
    "**Cons:**\n",
    "- The transformed features may have different ranges.\n",
    "- Sensitive to outliers, since these can significantly impact the mean and standard deviation (but it is less sensitive to outliers than min-max scaling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "603f8ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-1, 2, 3], [0.5, 6, 10], [0, 1, 8]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = [[-1, 2, 3], [0.5, 6, 10], [0, 1, 8]]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89cf1e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.33630621, -0.46291005, -1.35873244],\n",
       "       [ 1.06904497,  1.38873015,  1.01904933],\n",
       "       [ 0.26726124, -0.9258201 ,  0.33968311]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a715bdc8",
   "metadata": {},
   "source": [
    "**Robust scaling** — similar to standard scaling, but uses statistics that are more robust to outliers: from each feature, it subtracts its median and divides it by its inter-quantile range (IQR, the range between the first quartile and the third quartile).\n",
    "\n",
    "Mathematically, the transformation can be written as follows:\n",
    "\n",
    "$$x' = \\frac{x - x_{median}}{\\text{IQR}}$$\n",
    "\n",
    "**Pros:**\n",
    "- Less affected by outliers than standard scaling.\n",
    "\n",
    "**Cons:**\n",
    "- Does not normalize the data to have 0 mean and unit variance.\n",
    "- The transformed features may not have an intuitive interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17baef6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X = [[-1, 2, 3], [0.5, 6, 10], [0, 1, 8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb84bc10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.33333333,  0.        , -1.42857143],\n",
       "       [ 0.66666667,  1.6       ,  0.57142857],\n",
       "       [ 0.        , -0.4       ,  0.        ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7c4265",
   "metadata": {},
   "source": [
    "## Example: The Titanic Data Set\n",
    "We will now demonstrate the entire data preprocessing process on the titanic data set, available from Scikit-Learn. This data set describes the survival status of passengers on the Titanic. It contains 1,309 rows and has the following 14 features (including the label):\n",
    "\n",
    "- `pclass:` the passenger class (1 = 1st, 2 = 2nd, 3 = 3rd), indicates a socio-economic status (1st ~ Upper, 2nd ~ Middle, 3rd ~ Lower)\n",
    "- `name:` name of the passenger\n",
    "- `sex:` male or female\n",
    "- `age:` age in years (can be a fraction if age is less than 1)\n",
    "- `sibsp:` number of siblings/spouses aboard\n",
    "- `parch:` number of parents/children aboard\n",
    "- `ticket:` ticket number\n",
    "- `fare:` passenger's fare (in British pounds)\n",
    "- `cabin:` cabin number\n",
    "- `embarked:` port of embarkation (C = Cherbourg, Q = Queenstown, S = Southampton)\n",
    "- `boat:` the number of lifeboat (if survived)\n",
    "- `body:` body identification number (if did not survive and body was recovered)\n",
    "- `home.dest:` home/destination address\n",
    "- `survival:` the target label (0 = No, 1 = Yes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06842773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9037dd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_openml('titanic', version=1, return_X_y=True, as_frame=True, parser='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fcf8f1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass                                             name     sex      age  \\\n",
       "0       1                    Allen, Miss. Elisabeth Walton  female  29.0000   \n",
       "1       1                   Allison, Master. Hudson Trevor    male   0.9167   \n",
       "2       1                     Allison, Miss. Helen Loraine  female   2.0000   \n",
       "3       1             Allison, Mr. Hudson Joshua Creighton    male  30.0000   \n",
       "4       1  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female  25.0000   \n",
       "\n",
       "   sibsp  parch  ticket      fare    cabin embarked boat   body  \\\n",
       "0      0      0   24160  211.3375       B5        S    2    NaN   \n",
       "1      1      2  113781  151.5500  C22 C26        S   11    NaN   \n",
       "2      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "3      1      2  113781  151.5500  C22 C26        S  NaN  135.0   \n",
       "4      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "\n",
       "                         home.dest  \n",
       "0                     St Louis, MO  \n",
       "1  Montreal, PQ / Chesterville, ON  \n",
       "2  Montreal, PQ / Chesterville, ON  \n",
       "3  Montreal, PQ / Chesterville, ON  \n",
       "4  Montreal, PQ / Chesterville, ON  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be0df50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 13 columns):\n",
      " #   Column     Non-Null Count  Dtype   \n",
      "---  ------     --------------  -----   \n",
      " 0   pclass     1309 non-null   int64   \n",
      " 1   name       1309 non-null   object  \n",
      " 2   sex        1309 non-null   category\n",
      " 3   age        1046 non-null   float64 \n",
      " 4   sibsp      1309 non-null   int64   \n",
      " 5   parch      1309 non-null   int64   \n",
      " 6   ticket     1309 non-null   object  \n",
      " 7   fare       1308 non-null   float64 \n",
      " 8   cabin      295 non-null    object  \n",
      " 9   embarked   1307 non-null   category\n",
      " 10  boat       486 non-null    object  \n",
      " 11  body       121 non-null    float64 \n",
      " 12  home.dest  745 non-null    object  \n",
      "dtypes: category(2), float64(3), int64(3), object(5)\n",
      "memory usage: 115.4+ KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c46611a",
   "metadata": {},
   "source": [
    "Before we move to more advanced data exploration, let’s remove the following features, which are not relevant to the prediction task:\n",
    "\n",
    "- `name` and `ticket` are unique per passenger.\n",
    "- `cabin`, `boat`, and `body` contain a high percentage of missing values. In addition, 'boat' and 'body' are really part of the target, since we know that any passenger with a lifeboat number survived and any passenger with a body identification number did not survive.\n",
    "- `home.dest` contains a high percentage of unique values and does not seem to be relevant to the survival of the passenger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1b6f06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(['name', 'ticket', 'boat', 'body', 'home.dest'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51b3a9ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass     sex      age  sibsp  parch      fare    cabin embarked\n",
       "0       1  female  29.0000      0      0  211.3375       B5        S\n",
       "1       1    male   0.9167      1      2  151.5500  C22 C26        S\n",
       "2       1  female   2.0000      1      2  151.5500  C22 C26        S\n",
       "3       1    male  30.0000      1      2  151.5500  C22 C26        S\n",
       "4       1  female  25.0000      1      2  151.5500  C22 C26        S"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ce03229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(data=X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd468d7b",
   "metadata": {},
   "source": [
    "We can see that there are many outliers in the 'fare' column. This suggests that using a robust scaler to normalize the data would be a better choice than a standard scaler.\n",
    "\n",
    "Finally, since this is a classification problem, let’s check if it is balanced in terms of the class distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5573b211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived\n",
       "0    0.618029\n",
       "1    0.381971\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts() / y.value_counts().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4385500f",
   "metadata": {},
   "source": [
    "The classes are fairly balanced (61.8% of the passengers did not survive, and 38.2% survived)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1342dcbb",
   "metadata": {},
   "source": [
    "Let's identify the tasks we need to perform in order to prepare the data set for modeling:\n",
    "\n",
    "1. Impute the missing values in the columns 'age' (263 missing values), 'fare' (one missing value), and 'embarked' (two missing values). Note that 'embarked' is a categorical variable, therefore it requires a different imputation strategy. We will use a SimpleImputer with strategy='most_frequent' for the categorical feature, and a KNNImputer (with k = 5) for the numerical features.\n",
    "2. Encode the categorical features 'pclass', 'sex' and 'embarked' using one-hot encoding.\n",
    "3. Scale the numerical features 'age', 'sibsp', 'parch' and 'fare' using a robust scaler.\n",
    "\n",
    "Notice that we need to apply different transformations on the categorical and the numerical features. The basic pipeline in Scikit-Learn does not allow to apply a transformer to only a subset of the features. However, we can combine it with another class called `ColumnTransformer,` which allows different subsets of features to be transformed separately, and then it concatenates them to form a single feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fdbd8fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first define a pipeline to transform the categorical features:\n",
    "cat_features = ['pclass', 'sex', 'embarked']\n",
    "\n",
    "cat_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "561c1728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we define a pipeline to transform the numerical features:\n",
    "num_features = ['age', 'sibsp', 'parch', 'fare']\n",
    "\n",
    "num_transformer = Pipeline([\n",
    "    ('imputer', KNNImputer(n_neighbors=5)),\n",
    "    ('scaler', RobustScaler()) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "06a6c9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now combine the two pipelines using a ColumnTransformer, which associates each pipeline with its corresponding\n",
    "# set of features\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_transformer, num_features),\n",
    "    ('cat', cat_transformer, cat_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55abf658",
   "metadata": {},
   "source": [
    "Lastly, we build a pipeline that combines the column transformer and our classification model. In this example, we will use a random forest classifier with its default settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b881a0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    ('pre', preprocessor),\n",
    "    ('clf', RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afed3635",
   "metadata": {},
   "source": [
    "### Train-Test Split\n",
    "Before training the model, we split the data set into 80% training and 20% test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c945c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8c70adc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;pre&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   KNNImputer()),\n",
       "                                                                  (&#x27;scaler&#x27;,\n",
       "                                                                   RobustScaler())]),\n",
       "                                                  [&#x27;age&#x27;, &#x27;sibsp&#x27;, &#x27;parch&#x27;,\n",
       "                                                   &#x27;fare&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;onehot&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  [&#x27;pclass&#x27;, &#x27;sex&#x27;,\n",
       "                                                   &#x27;embarked&#x27;])])),\n",
       "                (&#x27;clf&#x27;, RandomForestClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;pre&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   KNNImputer()),\n",
       "                                                                  (&#x27;scaler&#x27;,\n",
       "                                                                   RobustScaler())]),\n",
       "                                                  [&#x27;age&#x27;, &#x27;sibsp&#x27;, &#x27;parch&#x27;,\n",
       "                                                   &#x27;fare&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;onehot&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  [&#x27;pclass&#x27;, &#x27;sex&#x27;,\n",
       "                                                   &#x27;embarked&#x27;])])),\n",
       "                (&#x27;clf&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">pre: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;, KNNImputer()),\n",
       "                                                 (&#x27;scaler&#x27;, RobustScaler())]),\n",
       "                                 [&#x27;age&#x27;, &#x27;sibsp&#x27;, &#x27;parch&#x27;, &#x27;fare&#x27;]),\n",
       "                                (&#x27;cat&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;onehot&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                 [&#x27;pclass&#x27;, &#x27;sex&#x27;, &#x27;embarked&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;age&#x27;, &#x27;sibsp&#x27;, &#x27;parch&#x27;, &#x27;fare&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNNImputer</label><div class=\"sk-toggleable__content\"><pre>KNNImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RobustScaler</label><div class=\"sk-toggleable__content\"><pre>RobustScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;pclass&#x27;, &#x27;sex&#x27;, &#x27;embarked&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('pre',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   KNNImputer()),\n",
       "                                                                  ('scaler',\n",
       "                                                                   RobustScaler())]),\n",
       "                                                  ['age', 'sibsp', 'parch',\n",
       "                                                   'fare']),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                  ('onehot',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  ['pclass', 'sex',\n",
       "                                                   'embarked'])])),\n",
       "                ('clf', RandomForestClassifier())])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "daa5722e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9713\n",
      "Test accuracy: 0.7977\n"
     ]
    }
   ],
   "source": [
    "train_acc = model.score(X_train, y_train)\n",
    "print(f'Train accuracy: {train_acc:.4f}')\n",
    "\n",
    "test_acc = model.score(X_test, y_test)\n",
    "print(f'Test accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bda283",
   "metadata": {},
   "source": [
    "It seems that the model is overfitting the training set to some degree. At this point, we might want to experiment with different transformers and imputers, try to extract new features from the data, and tune the hyperparameters of the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data Mining (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
