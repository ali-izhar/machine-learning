{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beed8845",
   "metadata": {},
   "source": [
    "# 1 - Face Recognition\n",
    "\n",
    "In face recognition, we want to identify a person from a database of $K$ persons, i.e. we want a single input image to map to the ID of one of the $K$ persons in the database (or no output if the person was not recognized). This is different from face verification where we compare the input image only to a single person and verify whether the input image is that of the claimed person."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d540a489",
   "metadata": {},
   "source": [
    "## 1.1 - One-shot Learning\n",
    "\n",
    "Up to this point we have only seen CNNs that needed a lot of pictures to be trained. However, because we usually don't have a lot of pictures of the same person, the problem with face recognition is that a CNN needs to be trained such that it is able to identify a person based on just a single picture. This process is called **one-shot learning.** Conventional CNNs are not suitable for this kind of task, not only because they require a huge amount of training data, but also because the whole network would need to be re-trained if we want to identify a new person who is just added to the database.\n",
    "\n",
    "When performing face recognition, we apply a similarity function \n",
    "\n",
    "$$d \\left( x^{(i)}, x^{(j)} \\right)$$\n",
    "\n",
    "that is able to calculate the (dis)similarity between two images: $x^{(i)}$ and $x^{(j)}$ as a value $\\tau$ (degree of difference). $\\tau$ is small for persons who look alike and large for different persons:\n",
    "\n",
    "$$d \\left( x^{(i)}, x^{(j)} \\right) = \\begin{cases}\n",
    "\\leq \\tau & \\text{(same person)} \\\\\n",
    "\\gt \\tau & \\text{(different persons)} \\\\\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940a88d3",
   "metadata": {},
   "source": [
    "## 1.2 - Siamese Networks\n",
    "\n",
    "One way to implement this similarity function is a siamese network. Such a network encodes an input image as a vector of arbitrary dimensions (e.g. 128 components). The network can be understood as a function $f(x)$ that encodes an image $x$ where similar pictures lead to similar encodings.\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"text-align\">\n",
    "    <img src=\"media/siamese-network-function.png\" width=600>\n",
    "</div>\n",
    "\n",
    "The similarity function can then be implemented as the vector norm of two image vectors/encodings:\n",
    "\n",
    "$$d \\left( x^{(i)}, x^{(j)} \\right) = || f\\left( x^{(i)} \\right) - f\\left( x^{(j)} \\right) ||_2^{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb887b07",
   "metadata": {},
   "source": [
    "## 1.3 - Triplet loss\n",
    "\n",
    "A siamese network should calculate similar image vectors for similar images and different vectors for different images. In other words: the distance between image vectors should be small for similar images and large for dissimilar images. We need to train the siamese network to exhibit this property. To do this, we can use the triplet loss function (TLF). When using the TLF, we define the image of one specific person as **anchor image $(A)$** and compare it with another image of the same person **(positive image $P$)** and an image of a different person **(negative image $N$).** Because of the initially formulated condition, the following equation needs to hold true:\n",
    "\n",
    "$$d(A, P) = || f(A) - f(P) ||_2^{2} \\leq || f(A) - f(N) ||_2^{2} = d(A, N)$$\n",
    "\n",
    "We can rearrange this equation and get:\n",
    "\n",
    "$$||f(A) - f(P)||_2^{2} - ||f(A) - f(N)||_2^{2} \\leq 0$$\n",
    "\n",
    "However, there a catch with this equation: We could achieve it to be true by simply \"calculating\" the zero vector for each image! In other words, if the network learns the trivial zero vector for all images or the \"same\" vector for all images, the different between them will always be less than or equan to zero.\n",
    "\n",
    "To prevent this, we add a parameter $\\alpha$ and get:\n",
    "\n",
    "$$||f(A) - f(P)||_2^{2} - ||f(A) - f(N)||_2^{2}  + \\alpha \\leq 0$$\n",
    "\n",
    "By rearranging it back to the original form we get:\n",
    "\n",
    "$$||f(A) - f(P)||_2^{2} + \\alpha \\leq ||f(A) - f(N)||_2^{2}$$\n",
    "\n",
    "The parameter $\\alpha$ is also called **margin.** The effect of this margin is that the value of $\\tau$ for pictures of the same person differs a lot from pictures of different persons (i.e. $d(A,P)$ is separated from $d(A,N)$ by a big margin).\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"text-align\">\n",
    "    <img src=\"media/tlf-distance-matrix.png\" width=600>\n",
    "</div>\n",
    "\n",
    "Considering all the points mentioned above we can define the TLF as follows:\n",
    "\n",
    "$$\\mathcal{L}(A, P, N) = \\max{\\left( 0, ||f(A) - f(P)||_2^{2} - ||f(A) - f(N)||_2^{2} + \\alpha \\right)}$$\n",
    "\n",
    "Maximizing the two values prevents the network from calculating negative losses. The total cost can be calculated as usual by summing the losses over all triplets:\n",
    "\n",
    "$$J = \\sum_{i=1}^m \\mathcal{L}\\left( A^{(i)}, P^{(i)}, N^{(i)} \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e095bda9",
   "metadata": {},
   "source": [
    "## 1.4 - TLF and Binary Classification\n",
    "\n",
    "The definition of the TLF function implies that in order to train a siamese network that exhibits the required properties, we need at least two different images of the same person. To ensure a strong discrimination, we should also consider triplets $(A,P,N)$ where $N$ is the image of a person who looks similar to $A$. That way we force the network to also learn to differentiate \"hard\" cases.\n",
    "\n",
    "In other words, during training, if $A,P,N$ are chosen randomly, then $d(A,P) + \\alpha \\leq d(A,N)$ is easily satisfied. Choose triplets that're \"hard\" to train on.\n",
    "\n",
    "An alternative approach for face recognition is to treat it as a binary classification problem. We could store precomputed image vectors in a database and would only have to calculate/compare a new person's image vector. We can do this by training a CNN which calculates a value close to 1 for pictures of the same person and a value close to 0 for pictures of different persons. The calculation of this value could be as follows:\n",
    "\n",
    "- Get the feature vectors/embeddings for each person from the CNN\n",
    "- To compute a binary label of either 1 (same person) or 0 (different persons), we can input the two feature vectors into a binary classifier as:\n",
    "\n",
    "$$\\hat{y} = \\sigma \\left( \\sum_{k=1}^K w_k \\cdot ||f\\left(x_k^{(i)}\\right) - f\\left(x_k^{(j)}\\right)|| + b \\right)$$\n",
    "\n",
    "Where we first find the element-wise difference of the two feature vectors , compute $W \\cdot X + b$ where $X$ is the computed difference, and then use sigmoid to output a binary label.\n",
    "\n",
    "Alternatively, we could use the $\\chi^2$-similarity instead of the element-wise similarity:\n",
    "\n",
    "$$\\hat{y} = \\sigma \\left( \\sum_{k=1}^K w_k \\cdot \\frac{ \\left( f\\left(x_k^{(i)}\\right) - f\\left(x_k^{(j)}\\right) \\right)^2}{f\\left(x_k^{(i)}\\right) + f\\left(x_k^{(j)}\\right) } \\right)$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data Mining (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
