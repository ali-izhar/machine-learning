{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6005a30f",
   "metadata": {},
   "source": [
    "# 9. Finding the Probability Distribution of a Function of Random Variables\n",
    "<hr>\n",
    "\n",
    "Consider random variables $Y_1,Y_2, \\cdots ,Y_n$ and a function $U(Y_1,Y_2, \\cdots ,Y_n)$, denoted simply as $U$. Then the three methods for finding the probability distribution of $U$ are as follows:\n",
    "\n",
    "1. **The method of distribution functions**\n",
    "This method is typically used when the Y's have continuous distributions. First, find the distribution function of $U$, $F_U(u)=P(U \\leq u)$. To do so, we must find the region in the $y_1,y_2, \\cdots ,y_n$ space for which $U \\leq u$ and then find $P(U \\leq u)$ by integrating $f(y_1,y_2, \\cdots ,y_n)$ over this region. The density function of $U$ is then obtained by differentiating the distribution function, $F_U (u)$.\n",
    "\n",
    "<br>\n",
    "\n",
    "2. **The method of transformations**\n",
    "If we are given a density function of a random variable $Y$, the method of transformations results in a general expression for the density of $U=h(Y)$ for an increasing or decreasing function $h(y)$ - i.e., the function is monotonic. \n",
    "\n",
    "<br>\n",
    "\n",
    "3. **The method of moment-generating functions**\n",
    "This method is based on a uniqueness theorem, which states that, if two random variables have identical moment-generating functions, the two random variables possess the same probability distributions. To use this method, we must find the moment-generating function for $U$ and compare it with the moment-generating functions for the common discrete and continuous random variables. If it is identical to one of these moment-generating functions, the probability distribution of $U$ can be identified because of the uniqueness theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b05010",
   "metadata": {},
   "source": [
    "### What is an indicator function?\n",
    "\n",
    "The interval (0,1) is called the **support space** as it's an important interval in most of the distributions. It is usually denoted by the **Indicator Function**, $I_{[0,1]}$.\n",
    "\n",
    "Therefore, instead of writing:\n",
    "\n",
    "$$f_U(u) = \\begin{cases}\n",
    "\\frac{3}{2} \\sqrt{u} & 0 \\leq u \\leq 1 \\\\\n",
    "0 & \\text{else} \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "We would write:\n",
    "\n",
    "$$f_U(u) = \\frac{3}{2} \\sqrt{u} I_{[0, 1]}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f33fe01",
   "metadata": {},
   "source": [
    "## 9.1 The Method of Distribution Functions\n",
    "<hr>\n",
    "\n",
    "Let,\n",
    "\n",
    "$$f(y) = \\begin{cases}\n",
    "\\frac{3}{2} y^2 & -1 \\leq y \\leq 1 \\\\\n",
    "\\\\\n",
    "0 & \\text{elsewhere} \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "**Question:** Find the density function of $U = 3Y$.\n",
    "\n",
    "$$U=3Y, \\quad U\\in(-3, 3)$$\n",
    "\n",
    "$$F_U(u) = P(U \\leq u) = P(3Y \\leq u) P\\left( U \\leq \\frac{u}{3} \\right) = \\int_{-1}^{u/3} \\frac{3}{2} y^2 dy = \\frac{u^3}{54} + \\frac{1}{2}$$\n",
    "\n",
    "Therefore,\n",
    "\n",
    "$$F_U(u) = \\begin{cases}\n",
    "\\frac{u^3}{54} + \\frac{1}{2} & -3 \\leq u \\leq 3 \\\\\n",
    "\\\\\n",
    "0 & u < -3 \\\\\n",
    "\\\\\n",
    "1 & u > 3\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Then,\n",
    "\n",
    "$$f_U(u) = \\frac{d}{du} F_U(u) = \\frac{u^2}{18}$$\n",
    "\n",
    "Hence,\n",
    "\n",
    "$$f_U(u) = \\begin{cases}\n",
    "\\frac{u^2}{18} & -3 \\leq u \\leq 3 \\\\\n",
    "\\\\\n",
    "0 & \\text{elsewhere} \\\\\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71b577a",
   "metadata": {},
   "source": [
    "## 9.2 The Method of Transformations\n",
    "<hr>\n",
    "\n",
    "The method of transformations is used for monotonous functions. Monotonic functions are invertible.\n",
    "\n",
    "- Increasing: if $y_1 \\leq y_2$, then $h(y_1) \\leq h(y_2)$\n",
    "- Decreasing: if $y_1 < y_2$, then $h(y_1 ) > h(y_2)$\n",
    "\n",
    "Suppose that $h(y)$ is an increasing function of $y$ and that $U=h(Y)$, where $Y$ has density function $f_Y (y)$. Then $h^{-1}(u)$ is an increasing function of $u$: if $u_1<u_2$, then $h^{-1} (u_1)=y_1<y_2=h^{-1} (u_2)$.\n",
    "\n",
    "$$\\{y: h(y) \\leq u_1\\} = \\{ y: y \\leq h^{-1}(u) \\}$$\n",
    "\n",
    "$$P(U \\leq u) = P \\left( y \\leq h^{-1}(u) \\right)$$\n",
    "\n",
    "Therefore, the cdf is given as:\n",
    "\n",
    "$$P(U \\leq u) = P[ h(Y) \\leq u] = P\\{ Y \\leq h^{-1}(u) \\}$$\n",
    "\n",
    "OR...\n",
    "\n",
    "$$F_U(u) = F_Y [h^{-1}(u)]$$\n",
    "\n",
    "$$f_U(u) = \\frac{d}{du} F_Y[h^{-1}(u)] = f_Y[h^{-1}(u)] \\frac{d}{du} h^{-1}(u)$$\n",
    "\n",
    "To simplify the notation:\n",
    "\n",
    "$$f_U(u) = f_Y[h^{-1}(u)] \\frac{dh^{-1}}{du}$$\n",
    "\n",
    "In general, for monotonically increasing or decreasing functions, since decreasing functions have a negative slope, we take the absolute value:\n",
    "\n",
    "$$f_U(u) = f_Y[h^{-1}(u)] \\left| \\frac{dh^{-1}}{du} \\right|$$\n",
    "\n",
    "<br>\n",
    "\n",
    "**Example:** Let,\n",
    "\n",
    "$$f(y) = \\begin{cases}\n",
    "\\frac{3}{2} y^2 & -1 \\leq y \\leq 1 \\\\\n",
    "\\\\\n",
    "0 & \\text{elsewhere} \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "**Question:** Find the density function of $U = 3Y$.\n",
    "\n",
    "$$U=3Y, \\quad U\\in(-3, 3)$$\n",
    "\n",
    "$$h^{-1}(u) = \\frac{u}{3}, \\quad \\frac{dh^{-1}}{du} = \\frac{1}{3}$$\n",
    "\n",
    "Therefore,\n",
    "\n",
    "$$f_Y[h^{-1}(u)] = f_Y\\left[\\frac{u}{3}\\right] = \\frac{3}{2} \\frac{u^2}{9} = \\frac{u^2}{9}$$\n",
    "\n",
    "And,\n",
    "\n",
    "$$f_U(u) = f_Y[h^{-1}(u)] \\left| \\frac{dh^{-1}}{du} \\right| = \\frac{u^2}{6} \\times \\frac{1}{3} = \\frac{u^2}{18}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e483f18d",
   "metadata": {},
   "source": [
    "## 9.3 The Method of Moment-Generating Functions\n",
    "<hr>\n",
    "\n",
    "Let $m_X (t)$ and $m_Y (t)$ denote the moment-generating functions of random variables $X$ and $Y$, respectively. If both moment-generating functions exist and $m_X (t)=m_Y (t)$ for all values of $t$, then $X$ and $Y$ have the same probability distribution.\n",
    "\n",
    "For a linear transformation, we know that if $U=aY+b$, then $m_U (t)=e^{tb} m_Y (at)$.\n",
    "\n",
    "Let $Y_1,Y_2, \\cdots ,Y_n$ be independent random variables with moment-generating functions $m_{Y_1}(t),m_{Y_2}(t), \\cdots ,m_{Y_n}(t)$, respectively. If $U=Y_1+Y_2+\\cdots+Y_n$, then:\n",
    "\n",
    "$$m_U(t) = E[e^{tU}] = E[e^{t(Y_1+Y_2+\\cdots+Y_n)}] = E[e^{tY_1} . e^{tY_2} \\cdots e^{tY_n}] = E[e^{tY_1}] . E[e^{tY_2}] \\cdots E[e^{tY_n}] = m_{Y_1}(t) . m_{Y_2}(t) \\cdots m_{Y_n}(t) = \\prod_{i=1}^n m_{Y_i}(t)$$\n",
    "\n",
    "<br>\n",
    "\n",
    "**Question:** What is the mgf of $\\bar{Y} = \\frac{U}{n} = ?$\n",
    "\n",
    "$$\\bar{Y} = \\frac{U}{n}, \\quad a=\\frac{1}{n}, b=0$$\n",
    "\n",
    "$$m_U(t) = e^{t(0)} m_Y \\left( \\frac{t}{n} \\right) = m_{Y_i} \\left( \\frac{t}{n} \\right)$$\n",
    "\n",
    "If all $Y_i$ are iid, then:\n",
    "\n",
    "$$m_U(t) = \\prod_{i=1}^n m_{Y_i} (t) = \\left[ m_{Y_i} (t) \\right]^n$$\n",
    "\n",
    "<br>\n",
    "\n",
    "<hr>\n",
    "\n",
    "### Binomial Distribution\n",
    "\n",
    "**Independent and Identically Distributed (iid)**\n",
    "\n",
    "If $Y_i \\sim \\text{Binomial}(n, p), \\quad i=1, 2, \\cdots, n$, then:\n",
    "\n",
    "$$m_Y(t) = (pe^t + q)^n$$\n",
    "\n",
    "$$m_U(t) = (pe^t + q)^{nm}$$\n",
    "\n",
    "Since the functional form is retained, $U$ is also a binomial.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Independent but not identical**\n",
    "\n",
    "For $Y_i, n=n_i, p_i = p$ for all $i$\n",
    "\n",
    "$$m_U(t) = (pe^t + q)^{n_1} .(pe^t + q)^{n_2} \\cdots (pe^t + q)^{n_m} = (pe^t + q)^{n_1+n_2+\\cdots+n_m}$$\n",
    "\n",
    "$$U \\sim \\text{Binomial}\\left( \\sum_{i=1}^m n_i, p \\right)$$\n",
    "\n",
    "<br>\n",
    "\n",
    "**Identical but not independent**\n",
    "For $Y_i, n_i = n, p=p_i$ for all $i$\n",
    "\n",
    "$$m_U(t) = (p_1 e^t + q_1)^{n} . (p_2 e^t + q_2)^{n} \\cdots (p_m e^t + q_m)^{n}$$\n",
    "\n",
    "Since the functional form is not retained, $U$ is not a binomial.\n",
    "\n",
    "<hr>\n",
    "\n",
    "### Geometric Distribution\n",
    "\n",
    "**Independent and Identically Distributed (iid)**\n",
    "\n",
    "If $Y_i \\sim \\text{Geometric}(p)$ where $p$ is the probability of success and $Y$ is the number of trials to get that first success.\n",
    "\n",
    "$$m_Y(t) = \\frac{pe^t}{1-qe^t}$$\n",
    "\n",
    "$$U = Y_1 + Y_2 + \\cdots + Y_n$$\n",
    "\n",
    "Where $Y_1$ is the number of trials to get the 1st success, $Y_2$ is the number of additional trials to get the 2nd success, and so on. In general, $Y_i$ is the number of additional trials between success $i-1$ and success $i$.\n",
    "\n",
    "$$m_U(t) = \\left( \\frac{pe^t}{1-qe^t} \\right)^n = \\text{Negative Binomial}$$\n",
    "\n",
    "<hr>\n",
    "\n",
    "### Normal Distribution\n",
    "\n",
    "**Independent and Identically Distributed (iid)**\n",
    "\n",
    "For a normal distribution,\n",
    "\n",
    "$$m_Y(t) = e^{\\mu t + \\frac{1}{2} t^2 \\sigma^2}$$\n",
    "\n",
    "A linear transformation, \n",
    "\n",
    "$$m_{a_i Y_i} (t) = e^{a_i \\mu_i t + \\frac{1}{2} t^2 a^2_{i} \\sigma^2_{i}} = N(a_i \\mu_i, a^2_i \\sigma^2_i)$$\n",
    "\n",
    "*Therefore, a linear transformation of the normal is also normal.*\n",
    "\n",
    "Let $Y_1, Y_2, \\cdots, Y_n$ be iid normal with $E(Y_i) = \\mu_i$ and $V(Y_i) = \\sigma^2_i$ for $i=1, 2, \\cdots, n$ and let $a_1, a_2, \\cdots, a_n$ be constants. If,\n",
    "\n",
    "$$U = \\sum_{i=1}^n a_i Y_i$$\n",
    "\n",
    "Then, $U$ is normally distributed with:\n",
    "\n",
    "$$m_U(t) = e^{t \\sum_{i=1}^n a_i \\mu_i + \\frac{t^2}{2} \\sum_{i=1}^n a^2_i \\sigma^2_i}$$\n",
    "\n",
    "$$E(U) = \\sum_{i=1}^n a_i \\mu_i, \\quad V(U) = \\sum_{i=1}^n a^2_i \\sigma^2_i$$\n",
    "\n",
    "For iid normal variables:\n",
    "\n",
    "$$m_U(t) = e^{na\\mu t + \\frac{1}{2} nt^2 a^2 \\sigma^2}$$\n",
    "\n",
    "$$E(Y_i) = na\\mu, \\quad V(Y_i) = na^2 \\sigma^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b86d278",
   "metadata": {},
   "source": [
    "## Standard Normal and $\\chi^2$ Relationship\n",
    "<hr>\n",
    "\n",
    "Let $Z \\sim N(0, 1)$. What is the distribution of $Z^2$?\n",
    "\n",
    "*Note: We cannot use the method of transformations because $Z$ is defined over $\\mathbb{R}$ but $Z^2$ is not invertible in that domain. We can use the method of distributions – however, we'd need polar coordinates to obtain a closed-form which is computationally tedious. Therefore, we're going to use the method of moment-generating functions.*\n",
    "\n",
    "For a normal random variable $Y$, the mgf is given as: \n",
    "\n",
    "$$m_Y(t) = e^{\\mu t + \\frac{1}{2} t^2 \\sigma^2}$$\n",
    "\n",
    "For a standard normal variable $Z$, the mgf is reduced to:\n",
    "\n",
    "$$m_Z(t) = e^{\\frac{t^2}{2}}$$\n",
    "\n",
    "Then,\n",
    "\n",
    "$$m_{Z^2}(t) = E\\left[ e^{tZ^2} \\right] = \\int_{-\\infty}^{\\infty} e^{tZ^2} f_Z(z) dz = \\int_{-\\infty}^{\\infty} e^{tZ^2} . \\frac{1}{\\sqrt{2\\pi}} e^{\\frac{-z^2}{2}} dz = \\int_{-\\infty}^{\\infty} \\frac{1}{\\sqrt{2\\pi}} e^{-\\left(\\frac{z^2}{2}\\right) (1-2t)} dz$$\n",
    "\n",
    "Notice that the integral converges only if exponential converges (remains negative). Therefore, for $(1-2t)>0$ or $t<\\frac{1}{2}$ the integral will converge with finite area. For a normal random variable, the exponential term is given as:\n",
    "\n",
    "$$\\frac{e^{\\frac{(y-\\mu)^2}{2\\sigma^2}}}{\\sigma \\sqrt{2\\pi}}$$\n",
    "\n",
    "In the integral above, we can reformat the integrand into the normal exponent by multiplying and dividing by the standard deviation:\n",
    "\n",
    "$$\\frac{e^{-\\frac{z^2}{2(1-2t)^{-1}}}}{\\sqrt{2\\pi}}, \\quad \\rightarrow \\text{here:} \\sigma^2 = (1-2t)^{-1}$$\n",
    "\n",
    "Multiplying and dividing by $\\sigma=\\sqrt{(1-2t)^{-1}} = (1-2t)^{-1/2}$:\n",
    "\n",
    "$$\\frac{(1-2t)^{-1/2}}{(1-2t)^{-1/2}} \\frac{e^{-\\frac{z^2}{2(1-2t)^{-1}}}}{\\sqrt{2\\pi}}, \\quad \\rightarrow \\text{here:} \\sigma^2 = (1-2t)^{-1}$$\n",
    "\n",
    "Plugging this back into the integral:\n",
    "\n",
    "$$m_{Z^2}(t) = \\int_{-\\infty}^{\\infty} \\frac{1}{\\sqrt{2\\pi}} e^{-\\left(\\frac{z^2}{2}\\right) (1-2t)} dz = (1-2t)^{-1/2} \\int_{-\\infty}^{\\infty} \\frac{1}{\\sqrt{2\\pi}} \\frac{e^{-\\frac{z^2}{2(1-2t)^{-1}}}}{(1-2t)^{-1/2} \\sqrt{2\\pi}} dz = (1-2t)^{-1/2} (1)$$\n",
    "\n",
    "Hence,\n",
    "\n",
    "$$m_{Z^2}(t) = (1-2t)^{-1/2} = \\text{Gamma}\\left(\\frac{1}{2}, 2\\right) = \\chi^2_{(1)}$$\n",
    "\n",
    "Therefore,\n",
    "\n",
    "<hr>\n",
    "\n",
    "$$Z^2 \\sim \\chi^2_{(1)}$$\n",
    "\n",
    "<hr>\n",
    "\n",
    "Let $Z_1, Z_2, \\cdots, Z_n$ be iid normal, then:\n",
    "\n",
    "$$U = Z_1^2 + Z_2^2 + \\cdots +Z_n^2$$\n",
    "\n",
    "$$m_U(t) = \\left[ (1-2t)^{-\\frac{1}{2}} \\right]^n = \\chi^2_{(n)}$$\n",
    "\n",
    "\n",
    "-\tThe sum of independent normal variables is normal.\n",
    "-\tThe sum of independent chi-square variables is chi-square."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data Mining (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
