{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "802fb08e",
   "metadata": {},
   "source": [
    "# 7. Variance, Covariance, and Correlation\n",
    "<hr>\n",
    "\n",
    "In statistics and probability theory, variance, covariance, and correlation are fundamental concepts that describe the relationships and behaviors of random variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab393f2c",
   "metadata": {},
   "source": [
    "## 7.1 Variance\n",
    "<hr>\n",
    "\n",
    "Variance is a measure of variability or spread of the distribution. Let $X$ be a random variable with $E(X)=\\mu$. Then the variance of $X$ is defined as:\n",
    "\n",
    "$$\\text{Var}(X) = E\\left[ (X - \\mu)^2 \\right]$$\n",
    "\n",
    "> If we think of the expected value $\\mu$ as the center of the distribution (as in the center of mass example previously), then Variance is the average distance (or squared distance) from the center for all realizations of $X$. A high variance indicates that the data points are spread out widely around the mean, while a low variance indicates they are clustered closely.\n",
    "\n",
    "\\begin{align}\n",
    "E \\left[ (X - \\mu)^2 \\right] &= E [ X^2 - 2\\mu X + \\mu^2 ] \\\\\n",
    "&= E(X^2) - 2\\mu E(X) + E(\\mu^2) \\\\\n",
    "&= E(X^2) - 2\\mu (\\mu) + \\mu^2 \\\\\n",
    "&= E(X^2) - 2\\mu^2 + \\mu^2 \\\\\n",
    "&= E(X^2) - \\mu^2    \n",
    "\\end{align}\n",
    "\n",
    "Therefore, variance is also given as:\n",
    "\n",
    "$$\\text{V}(X) = E(X^2) - \\mu^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e27fa85",
   "metadata": {},
   "source": [
    "## 7.2 Covariance\n",
    "<hr>\n",
    "\n",
    "Covariance measures how much two random variables change together, or the extent to which one variable's deviation from its mean matches the deviation of another.\n",
    "\n",
    "$$\\text{Cov}(X,Y) = E\\left[ (X-\\mu_X) (Y-\\mu_Y) \\right]$$\n",
    "\n",
    "- Positive covariance implies that as $X$ increases, $Y$ tends to increase.\n",
    "- Negative covariance implies that as $X$ increases, $Y$ tends to decrease.\n",
    "- Zero covariance implies that there is no linear relationship between $X$ and $Y$.\n",
    "\n",
    "If $X$ and $Y$ are independent, then:\n",
    "\n",
    "$$\\text{Cov}(X, Y) = E(X) E(Y) - \\mu_X \\mu_Y$$\n",
    "\n",
    "<br>\n",
    "\n",
    "*Remarks:*\n",
    "\n",
    "- $-\\sigma_1 \\sigma_2 < \\text{Cov}(X,Y) < \\sigma_1 \\sigma_2$\n",
    "- If small values of one variable, $X$, occur in conjunction with small values of another variable, $Y$, then $\\text{Cov}(X,Y)>0$. For instance, if $X < \\mu_X, Y < \\mu_Y$, then\n",
    "\n",
    "$$ E\\left[ (X-\\mu_X) (Y-\\mu_Y) \\right] = E[ (-) (-) ] = + $$\n",
    "\n",
    "- If large values of one variable, $X$, occur in conjunction with large values of another variable, $Y$, then $\\text{Cov}(X,Y)>0$.\n",
    "\n",
    "$$ E\\left[ (X-\\mu_X) (Y-\\mu_Y) \\right] = E[ (+) (+) ] = + $$\n",
    "\n",
    "- If large values of one variable, $X$, occur in conjunction with smaller values of another variable, $Y$, then $\\text{Cov}(X,Y)<0$.\n",
    "\n",
    "$$ E\\left[ (X-\\mu_X) (Y-\\mu_Y) \\right] = E[ (+) (-) ] = - $$\n",
    "\n",
    "<br>\n",
    "\n",
    "**Theorem:** The covariance of $X$ and $Y$ is given as:\n",
    "\n",
    "$$\\text{Cov}(X,Y)=E(X.Y) - \\mu_X  \\mu_Y$$\n",
    "\n",
    "*Proof.*\n",
    "\n",
    "\\begin{align}\n",
    "\\text{Cov}(X,Y) &= E\\left[ (X-\\mu_X) (Y-\\mu_Y) \\right] \\\\\n",
    "&= E[XY - X \\mu_Y - Y \\mu_X + \\mu_X \\mu_Y] \\\\\n",
    "&= E(XY) - E(X \\mu_Y) - E(Y \\mu_X) + E(\\mu_X \\mu_Y) \\\\\n",
    "&= E(XY) - \\mu_Y E(X) - \\mu_X E(Y) + \\mu_X \\mu_Y \\\\\n",
    "&= E(XY) - \\mu_Y \\mu_X - \\mu_X \\mu_Y + \\mu_X \\mu_Y \\\\\n",
    "&= E(XY) - \\mu_X \\mu_Y \\\\\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "### 7.2.1 Properties of Covariance\n",
    "\n",
    "\\begin{align}\n",
    "\\text{Cov}(X,Y) &= \\text{Cov}(Y,X) \\\\\n",
    "\\text{Cov}(X,X) &= E\\left[ (X-\\mu_X) (X-\\mu_X) \\right] = E(X-\\mu_X)^2 = \\text{Var}(X) \\\\\n",
    "\\text{Cov}(aX, Y) &= a \\ \\text{Cov}(X,Y) \\\\\n",
    "\\text{Var}(a X_1 + b X_2) &= a^2 \\ \\text{Var}(X_1) + b^2 \\ \\text{Var}(X_2) + 2(a)(b) \\text{Cov}(X_1, X_2) \\\\\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b2fbf6",
   "metadata": {},
   "source": [
    "## 7.3 Correlation\n",
    "<hr>\n",
    "\n",
    "Correlation is a normalized form of covariance that measures the strength and direction of a linear relationship between two random variables.\n",
    "\n",
    "$$\\text{Corr}(X,Y) = \\frac{\\text{Cov}(X,Y)}{\\sigma_X \\sigma_Y}$$\n",
    "\n",
    "- $ -1 \\leq \\rho(X, Y) \\leq 1$\n",
    "- If $\\rho(X,Y) = 0$, then $\\text{Cov}(X,Y)=0$ i.e., there is no linearity between $X$ and $Y$. Note that the absence of linearity does not mean independence of variables. Take, for instance, the joint of $X$ and $Y$ that is in the shape of a parabola. The linearity is zero in this case, but the variables are not independent.\n",
    "- If $X$ and $Y$ are independent, then the $\\text{Cov}(X,Y)=0$.\n",
    "\n",
    "Correlations:\n",
    "-\tHigh = 0.9 and above\n",
    "-\tModerate = 0.5 to 0.8\n",
    "-\tLow = 0.5 and below"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data Mining (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
