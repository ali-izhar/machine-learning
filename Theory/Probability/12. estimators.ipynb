{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e424182",
   "metadata": {},
   "source": [
    "# 12. Estimators, Properties of Point Estimators and Methods of Estimation\n",
    "<hr>\n",
    "\n",
    "An **estimator** is a rule, often expressed as a formula, that tells us how to calculate the value of an estimate based on the measurements contained in a sample.\n",
    "\n",
    "Let $\\hat{\\theta}$ be a point estimate for a parameter $\\theta$. Then $\\hat{\\theta}$ is an unbiased estimator if $E(\\hat{\\theta})=\\theta$. If $E(\\hat{\\theta}) \\neq \\theta$, then $\\hat{\\theta}$ is said to be biased.\n",
    "\n",
    "The **bias** of a point estimator $\\hat{\\theta}$ is given by:\n",
    "\n",
    "$$B(\\hat{\\theta}) = E(\\hat{\\theta}) - \\theta$$\n",
    "\n",
    "- If $B(\\hat{\\theta}) < \\theta$, then $\\hat{\\theta}$ tends to underestimate $\\theta$.\n",
    "- If $B(\\hat{\\theta}) > \\theta$, then $\\hat{\\theta}$ tends to overestimate $\\theta$.\n",
    "\n",
    "The **mean square error** of a point estimator $\\hat{\\theta}$ is:\n",
    "\n",
    "$$\\text{MSE} = E\\left[ (\\hat{\\theta} - \\theta)^2 \\right] = V(\\hat{\\theta}) + \\left[ B(\\hat{\\theta}) \\right]^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62a3271",
   "metadata": {},
   "source": [
    "## 12.1 Estimating Variance\n",
    "<hr>\n",
    "\n",
    "Sample variance could be estimated as:\n",
    "\n",
    "$$s^2 = \\frac{1}{n-1} \\sum_{i=1}^n (Y_i - \\bar{Y})^2$$\n",
    "\n",
    "OR...\n",
    "\n",
    "$$s'^2 = \\frac{1}{n} \\sum_{i=1}^n (Y_i - \\bar{Y})^2$$\n",
    "\n",
    "Which one is an unbiased estimator?\n",
    "\n",
    "*Note that there is no assumption on the shape of the distribution and $E(Y_i)=\\mu$ and $V(Y_i)=\\sigma^2$.*\n",
    "\n",
    "$$s^2 = \\frac{1}{n-1} \\sum_{i=1}^n (Y_i - \\bar{Y})^2$$\n",
    "\n",
    "Where:\n",
    "\n",
    "$$\\sum_{i=1}^n (Y_i - \\bar{Y})^2 = \\sum_{i=1}^n Y_i^2 - n\\bar{Y}$$\n",
    "\n",
    "$$E\\left[ \\sum_{i=1}^n Y_i^2 - n\\bar{Y} \\right] = \\sum_{i=1}^n E(Y_i^2) - n E(\\bar{Y}^2)$$\n",
    "\n",
    "Where:\n",
    "\n",
    "\\begin{align}\n",
    "E(Y_i)^2 &= V(Y_i) + [E(Y_i)]^2 = \\sigma^2 + \\mu^2 \\\\\n",
    "E(\\bar{Y}^2) &= V(\\bar{Y}) + [E(\\bar{Y})]^2 = \\frac{\\sigma^2}{n} + \\mu^2 \\\\\n",
    "\\end{align}\n",
    "\n",
    "$$E\\left[ \\sum_{i=1}^n Y_i^2 - n\\bar{Y} \\right] = \\sum_{i=1}^n E(Y_i^2) - n E(\\bar{Y}^2) = n(\\sigma^2 + \\mu^2) - n \\left( \\frac{\\sigma^2}{n} + \\mu^2 \\right) = (n-1) \\sigma^2 $$\n",
    "\n",
    "Therefore,\n",
    "\n",
    "$$E(s^2) = E\\left[ \\frac{1}{n-1} (n-1) \\sigma^2 \\right] = E(\\sigma^2) = \\sigma^2$$\n",
    "\n",
    "$$E(s'^2) = E\\left[ \\frac{1}{n} (n-1) \\sigma^2 \\right] = E(\\sigma^2 - \\frac{\\sigma^2}{n}) = \\sigma^2 - \\frac{\\sigma^2}{n}$$\n",
    "\n",
    "Hence, $s^2$ is an unbiased estimator of $\\sigma^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b1568f",
   "metadata": {},
   "source": [
    "## 12.2 The Method of Moments (MOM)\n",
    "<hr>\n",
    "\n",
    "One of the oldest methods for deriving point estimators is the method of moments. Recall that the $k$th moment of a random variable, taken about the origin, is:\n",
    "\n",
    "$$u'_k = E(Y^k)$$\n",
    "\n",
    "The corresponding $k$th sample moment is the average:\n",
    "\n",
    "$$m'_k = \\frac{1}{n} \\sum_{i=1}^n Y_i^k$$\n",
    "\n",
    "Sample moments should provide good estimates of the corresponding population moments. That is, $m'_k$ should be a good estimator of $\\mu'_k$. Then, because the population moments are functions of the population parameters, we can equate corresponding population and sample moments and solve for the desired estimators.\n",
    "\n",
    "***Choose as estimates those values of the parameters that are solutions of the equations $Î¼'_k=m'_k$, for $k=1,2,\\cdots,t$ where $t$ is the number of parameters to be estimated.***\n",
    "\n",
    "<br>\n",
    "\n",
    "**Example:** Let $Y_1, Y_2, \\cdots, Y_n$ denote a random sample from the pdf:\n",
    "\n",
    "$$f(y \\mid \\theta) = \\begin{cases}\n",
    "(\\theta+1)y^\\theta & 0<y<1; \\theta>-1 \\\\\n",
    "0 & \\text{elsewhere}\\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Find an estimator for $\\theta$ by the method of moments. Show that the estimator is consistent.\n",
    "\n",
    "Since there is onlyh one parameter $\\theta$, we find the first moment for $t=1$ as:\n",
    "\n",
    "$$\\mu'_1 = E(Y) \\quad \\quad m'_1 = \\frac{1}{n} \\sum_{i=1}^n Y_i = \\bar{Y}$$\n",
    "\n",
    "Setting $\\mu'_1$ equal to $m'_1$:\n",
    "\n",
    "$$E(Y) = \\bar{Y}$$\n",
    "\n",
    "Finding $E(Y)$ as:\n",
    "\n",
    "$$E(Y) = \\int_{0}^1 y(\\theta+1)y^\\theta dy = (\\theta + 1) \\int_{0}^1 y^{\\theta+1} dy = \\frac{\\theta+1}{\\theta+2}$$\n",
    "\n",
    "Therefore,\n",
    "\n",
    "$$\\frac{\\theta+1}{\\theta+2} = \\bar{Y}$$\n",
    "\n",
    "Solving for $\\theta$:\n",
    "\n",
    "$$\\hat{\\theta}_{\\text{MOM}} = \\frac{2 \\bar{Y} - 1}{1 - \\bar{Y}}$$\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922efae4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d36a90b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c705b56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data Mining (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
