{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8927acf",
   "metadata": {},
   "source": [
    "# 8. Conditional Expectations, Moments, and Moment-Generating Functions (MGFs)\n",
    "\n",
    "<hr>\n",
    "\n",
    "Conditional expectation refers to the expected value of a random variable given that certain conditions are met or certain values are observed in another random variable.\n",
    "\n",
    "The conditional expectation of a random variable $X$ given $Y$ is denoted as $E(X \\mid Y)$. It represents the average or mean of $X$ when $Y$ is known.\n",
    "\n",
    "\\begin{align}\n",
    "E(X \\mid Y=y) &= \\sum_{\\forall{x}} x . P(X=x \\mid Y=y) & \\text{(discrete)} \\\\\n",
    "&= \\sum_{\\forall{x}} x \\frac{P(x,y)}{P_Y(y)} \\\\\n",
    "\\\\\n",
    "E(X \\mid Y=y) &= \\int_{\\forall{x}} x . f_{X \\mid Y} (x \\mid y) dx & \\text{(continuous)} \\\\\n",
    "&= \\int_{\\forall{x}} x \\frac{f(x,y)}{f_Y(y)} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b00311",
   "metadata": {},
   "source": [
    "## 8.1 Computing Expectations using Conditioning\n",
    "<hr>\n",
    "\n",
    "$$E[X] = E_Y [E_X [X \\mid Y=y ]]$$\n",
    "\n",
    "*Proof.* \n",
    "\n",
    "\\begin{align}\n",
    "E_Y [ E_X [X \\mid Y-y ]] &= \\sum_{\\forall{y}} E[X \\mid Y=y] . P(Y=y) \\\\\n",
    "&= \\sum_{\\forall{y}} \\sum_{\\forall{x}} x P(X \\mid Y) . P(Y=y) \\\\\n",
    "&= \\sum_{\\forall{y}} \\sum_{\\forall{x}} x \\frac{P(x,y)}{P_Y(y)} P(Y=y) \\\\\n",
    "&= \\sum_{\\forall{y}} \\sum_{\\forall{x}} x P(x,y) \\\\\n",
    "&= \\sum_{\\forall{x}} x \\sum_{\\forall{y}} P(x,y) \\\\\n",
    "&= \\sum_{\\forall{y}} x P_X(x,y) \\\\\n",
    "&= E[X] \\\\\n",
    "\\end{align}\n",
    "\n",
    "If $X$ and $Y$ are independent, then:\n",
    "\n",
    "$$E[X \\mid Y] = E[X]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768b50e9",
   "metadata": {},
   "source": [
    "## 8.2 Moments\n",
    "<hr>\n",
    "\n",
    "In statistics, moments are quantitative measures related to the shape of a distribution's graph. For each integer $n$, the $n$th moment of a random variable $X$ is defined as:\n",
    "\n",
    "$$\\mu'_{n} = E[X^n]$$\n",
    "\n",
    "The $n$th central moment of $X$ is defined as:\n",
    "\n",
    "$$\\mu_n = E[X-\\mu]^n$$\n",
    "\n",
    "- **First Moment (Mean):** The first moment is the expected value or the mean of the distribution.\n",
    "- **Second Moment (Variance):** The second central moment is the variance.\n",
    "- **Higher Moments:** The third moment is related to skewness (asymmetry) and the fourth moment to kurtosis (tailedness). Higher moments are used less frequently but can describe more complex aspects of the distribution's shape.\n",
    "\n",
    "$$E[X^n] = \\sum_{\\forall{x}} x^n p(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d80e5fd",
   "metadata": {},
   "source": [
    "## 8.3 Moment-Generating Functions (MGFs)\n",
    "<hr>\n",
    "\n",
    "Let $X$ be a random variable with density $f(x)$, then the moment generating function (mgf) is defined as the **Laplace transformation** of $f(x)$. \n",
    "\n",
    "Let the mgf of $X$ is denoted as $M_X (t)$.\n",
    "\n",
    "$$M_X(t) = E_X(e^{tx}) = \\sum_{\\forall{x}} e^{tx} f(x) = \\int_{\\forall{x}} e^{ty} f(x) dx $$\n",
    "\n",
    "**Theorem:** If $X$ is a random variable with MGF $M_X(t)$, then\n",
    "\n",
    "$$ E[X^n] = \\left. \\frac{d^n}{dt^n} M_X(t) \\right|_{t=0} $$\n",
    "\n",
    "*Proof.*\n",
    "\n",
    "$$\\frac{d}{dt} M_X(t) = \\frac{d}{dt} \\int_{-\\infty}^{\\infty} e^{tx} f(x) dx = \\int_{-\\infty}^{\\infty} xe^{tx} f(x) dx$$\n",
    "\n",
    "Evaluating at $t=0$:\n",
    "\n",
    "$$\\left. \\frac{d}{dt} M_X(t) \\right|_{t=0} = E[X]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a470739",
   "metadata": {},
   "source": [
    "## 8.4 MGFs of Random Variables\n",
    "<hr>\n",
    "\n",
    "### 8.4.1 MGF of Binomial\n",
    "If $X \\sim \\text{Binomial}(n,p)$, then $p(x) = \\binom{n}{x}p^x (1-p)^{n-x}$. Therefore,\n",
    "\n",
    "$$M_X(t) = E_X(e^{tx}) = \\sum_{x} e^{tx} p(x) = \\sum_{x=0}^n e^{tx} \\binom{n}{x}p^x (1-p)^{n-x} = \\sum_{x=0}^n \\binom{n}{x} (e^t p)^x (1-p)^{n-x}$$\n",
    "\n",
    "Since,\n",
    "\n",
    "$$(a+b)^n = \\sum_{i=1}^n \\binom{n}{i}a^i b^{n-i}$$\n",
    "\n",
    "<hr>\n",
    "$$M_X(t) = \\sum_{x=0}^n \\binom{n}{x} (e^t p)^x (1-p)^{n-x} = (e^t p + 1-p)^n) = (pe^t + q)^n$$\n",
    "<hr>\n",
    "\n",
    "**Verify** that $E(X)=np$ and $\\text{Var}(X)=np(1-p)$.\n",
    "\n",
    "By definition, the first moment of $X$ is the $E[X]$ and the second central moment is $Var(X)$.\n",
    "\n",
    "$$E[X] = \\left. \\frac{d}{dt} (pe^t + q)^n \\right|_{t=0} = np$$\n",
    "\n",
    "$$E[X^2] = \\left. \\frac{d^2}{dt^2} (pe^t + q)^n \\right|_{t=0} = np(np+q)$$\n",
    "\n",
    "Therefore,\n",
    "\n",
    "$$\\text{Var}(X) = E[X^2] - \\mu^2 = np(np+q) - (np)^2 = npq$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1986d0ab",
   "metadata": {},
   "source": [
    "### 8.4.2 MGF of Poisson\n",
    "If $X \\sim \\text{Poisson}(\\lambda)$, then $p(x) = e^{-\\lambda} \\frac{\\lambda^x}{x!}$. Therefore,\n",
    "\n",
    "$$M_X(t) = E_X(e^{tx}) = \\sum_{x} e^{tx} p(x) = \\sum_{x} e^{tx} e^{-\\lambda} \\frac{\\lambda^x}{x!} = e^{-\\lambda} \\sum_{x} e^{tx} \\frac{\\lambda^x}{x!} = e^{-\\lambda} \\sum_{x} \\frac{(e^t\\lambda)^x}{x!}$$\n",
    "\n",
    "Since,\n",
    "\n",
    "$$\\sum_{x=0}^\\infty \\frac{x^n}{n!} = e^x$$\n",
    "\n",
    "<hr>\n",
    "\n",
    "$$M_X(t) = e^{-\\lambda} \\sum_{x} \\frac{(e^t \\lambda)^x}{x!} = e^{-\\lambda} e^{e^t \\lambda} = e^{\\lambda(e^t-1)}$$\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Verify** that $E(X)=\\lambda$ and $\\text{Var}(X)=\\lambda$.\n",
    "\n",
    "By definition, the first moment of $X$ is the $E[X]$ and the second central moment is $Var(X)$.\n",
    "\n",
    "$$E[X] = \\left. \\frac{d}{dt} e^{\\lambda(e^t-1)} \\right|_{t=0} = \\lambda$$\n",
    "\n",
    "$$E[X^2] = \\left. \\frac{d^2}{dt^2} e^{\\lambda(e^t-1)} \\right|_{t=0} = \\lambda^2 + \\lambda$$\n",
    "\n",
    "Therefore,\n",
    "\n",
    "$$\\text{Var}(X) = E[X^2] - \\mu^2 = \\lambda^2 + \\lambda - \\lambda^2 = \\lambda$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bdffbe",
   "metadata": {},
   "source": [
    "### 8.4.3 MGF of Exponential\n",
    "\n",
    "If $X \\sim \\text{exp}(\\lambda)$, then $f(x) = \\lambda e^{-\\lambda x} = \\frac{1}{\\beta} e^{-y/\\beta}$ where $\\lambda = \\frac{1}{\\beta}$ such that $\\beta>0, y \\geq 0$.\n",
    "\n",
    "$$M_X(t) = E_X(e^{tx}) = \\int_{0}^\\infty e^{tx} \\left( \\frac{1}{\\beta} e^{\\frac{-y}{\\beta}} \\right) dx = \\frac{1}{\\beta} \\int_0^\\infty e^{\\frac{- (1-\\beta t)y}{\\beta}} dx = \\frac{1}{\\beta} \\int_0^\\infty e^{\\frac{-y}{\\left( \\frac{\\beta}{1-\\beta t} \\right)}} dx$$\n",
    "\n",
    "*Note: $e^{\\frac{-y}{\\left( \\frac{\\beta}{1-\\beta t} \\right)}}$ is the exponential kernel. Therefore,* \n",
    "\n",
    "$$\\int_0^\\infty e^{\\frac{-y}{\\left( \\frac{\\beta}{1-\\beta t} \\right)}} dx = \\frac{\\beta}{1- \\beta t}$$\n",
    "\n",
    "<hr>\n",
    "\n",
    "$$M_X(t) = \\frac{1}{\\beta} \\left( \\frac{\\beta}{1-\\beta t} \\right) = \\frac{1}{1-\\beta t}$$\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Verify** that $E(X)=\\beta$ and $\\text{Var}(X)=\\beta^2$.\n",
    "\n",
    "By definition, the first moment of $X$ is the $E[X]$ and the second central moment is $Var(X)$.\n",
    "\n",
    "$$E[X] = \\left. \\frac{d}{dt}  \\frac{1}{1-\\beta t} \\right|_{t=0} = \\beta$$\n",
    "\n",
    "$$E[X^2] = \\left. \\frac{d^2}{dt^2} \\frac{1}{1-\\beta t} \\right|_{t=0} = 2 \\beta^2$$\n",
    "\n",
    "Therefore,\n",
    "\n",
    "$$\\text{Var}(X) = E[X^2] - \\mu^2 = 2 \\beta^2 -\\beta^2 = \\beta^2$$\n",
    "\n",
    "In general, the moments of the exponential distribution are:\n",
    "\n",
    "$$E(X^k) = k! \\beta^k$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292a8a97",
   "metadata": {},
   "source": [
    "## Table of MGFs\n",
    "Commonly used distributions and their corresponding MGFs are given below:\n",
    "\n",
    "<hr>\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"media/discrete_mgfs.png\" width=900>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "<hr>\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"media/cont_mgfs.png\" width=900>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6881ab",
   "metadata": {},
   "source": [
    "- $\\chi^2$ and Exponential are special cases of the Gamma.\n",
    "- $\\chi^2=\\text{Gamma}(\\alpha = \\nu/2, \\beta=2)$\n",
    "- $\\text{Exponential}=\\text{Gamma}(\\alpha=1,\\beta)$\n",
    "- Poisson is the only distribution for which $\\mu=\\sigma^2$\n",
    "\n",
    "**Question:** Identify the distribution and values of the mean and variance.\n",
    "\n",
    "\\begin{align}\n",
    "(1-2t)^{-5} \\\\\n",
    "\\text{This is Gamma}(5, 2) \\\\\n",
    "\\mu = \\alpha \\beta = 10 \\\\\n",
    "\\sigma^2 = \\alpha \\beta^2 = 5(4) = 20 \\\\\n",
    "\\end{align}\n",
    "\n",
    "<br>\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{0.3e^t}{1-0.7e^t} \\\\\n",
    "\\text{This is Geometric}(0.3) \\\\\n",
    "\\mu = \\frac{1}{p} = \\frac{1}{0.3} \\\\\n",
    "\\sigma^2 = \\frac{1-p}{p^2} = \\frac{0.7}{0.3^2} \\\\\n",
    "\\end{align}\n",
    "\n",
    "<br>\n",
    "\n",
    "\\begin{align}\n",
    "e^{5t+18t^2} \\\\\n",
    "\\text{This is Normal}(5, 6) \\\\\n",
    "\\mu = 5 \\\\\n",
    "\\sigma^2 = 6 \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b58f766",
   "metadata": {},
   "source": [
    "## Linear Transformations using a Moment-Generating Function\n",
    "<hr>\n",
    "\n",
    "**Example:** $Y=\\text{Poisson}(\\lambda=4)$\n",
    "\n",
    "Consider the transformation: $W=2Y+5$. What is the MGF of $W = ?$\n",
    "\n",
    "The MGF of $Y$ is $e^{\\lambda (e^t - 1)} = e^{4 (e^t -1)}$\n",
    "\n",
    "$$W=aY+b \\quad a=2, b=5$$\n",
    "\n",
    "***Then, two random variables are equal if and only if they have the same moment generating function.***\n",
    "\n",
    "$$M_W (t) = M_{aY+b} (t)$$\n",
    "\n",
    "$$M_W (t) = E(e^{tW}) = E(e^{t(aY+b)}) = E(e^{taY} . e^{tb}) = e^{tb} E(e^{taY}) = e^{tb} M_Y (ta)$$\n",
    "\n",
    "For $\\lambda=4, a=2, b=5, M_Y(t) = e^{4(e^t - 1)}$:\n",
    "\n",
    "$$M_W(t) = e^{5t} M_Y(2t) = e^{5t} e^{4 (e^{2t} - 1} = e^{4e^{2t}+5t-4}$$\n",
    "\n",
    "Since $M_W (t)$ is not the same structure as the MGF of a Poisson, the random variable $W$ is not a Poisson. We can't recognize the pmf or pdf of $W$.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Example:** $Y \\sim N(3, 2)$\n",
    "\n",
    "Consider the transformation: $W=4Y-7$. What is the MGF of $W = ?$\n",
    "\n",
    "The MGF of $Y$ is $e^{\\mu t + \\frac{t^2 \\sigma^2}{2}} = e^{3t + 2t^2}$\n",
    "\n",
    "$$W = 4Y-7 \\quad a=4, b=-7$$\n",
    "\n",
    "$$M_W(t) = e^{tb} M_Y(ta) = e^{-7t} e^{12t+32t^2} = e^{5t+32t^2} = N(\\mu=5, \\sigma^2 = 64)$$\n",
    "\n",
    "-\tAny linear transformation of a normal distribution is also normal.\n",
    "-\tAny linear transformation of a uniform distribution keeps the same functional form.\n",
    "-\tOther distributions will retain the functional form under certain conditions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data Mining (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
