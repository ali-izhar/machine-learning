{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43d97c11",
   "metadata": {},
   "source": [
    "# 4. Probability Models for a Discrete Random Variable\n",
    "<hr>\n",
    "\n",
    "1. Bernoulli random variable\n",
    "2. Binomial random variable\n",
    "3. Poisson random variable\n",
    "4. Geometric random variable\n",
    "5. Hyper geometric random variable\n",
    "6. The negative binomial random variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f91db69",
   "metadata": {},
   "source": [
    "## 4.1 Bernoulli Random Variable\n",
    "<hr>\n",
    "\n",
    "A Bernoulli random variable represents an experiment that results in two outcomes, which can be classified as either a success or a failure.\n",
    "\n",
    "**Example:** Consider an experiment of tossing a fair coin. We can define a Bernoulli random variable $X$ to represent the outcome of this experiment, where $X$ takes the value of either 0 or 1.\n",
    "- Let $X=0$ represent the outcome being a failure (e.g., tails).\n",
    "- Let $X=1$ represent the outcome being a success (e.g., heads).\n",
    "\n",
    "A Bernoulli distribution is characterized by a single parameter $p$, which is the probability of success.\n",
    "\n",
    "$$X \\sim \\text{Bernoulli}(p)$$\n",
    "\n",
    "### 4.1.1 PMF of Bernoulli\n",
    "The PMF of a Bernoulli random variable defines the probability of each of its possible outcomes. It is given by:\n",
    "\n",
    "\\begin{align}\n",
    "P(X=1) &= p && \\text{(probability of success)} \\\\\n",
    "P(X=0) &= 1 - p && \\text{(probability of failure)}\n",
    "\\end{align}\n",
    "\n",
    "Here, $p$ is the probability of the event being a success (e.g., getting heads in a coin toss), and $1−p$ is the probability of it being a failure.\n",
    "\n",
    "### 4.1.2 Expected Value and Variance of Bernoulli\n",
    "\n",
    "$$E(X)=1(p)+0(1-p)=p \\quad \\quad \\text{Var}(X)=E(X^2 )-\\mu^2=p-p^2=p(1-p)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5ffdac",
   "metadata": {},
   "source": [
    "## 4.2 Binomial Random Variable\n",
    "<hr>\n",
    "\n",
    "A Binomial Random Variable can be thought of as a generalization of the Bernoulli Random Variable. It describes the number of successes in a fixed number of independent Bernoulli trials.\n",
    "\n",
    "- **Bernoulli Trial:** A single experiment with two outcomes: success (probability $p$) and failure (probability $1−p$).\n",
    "- **Binomial Setting:** Consists of $n$ independent Bernoulli trials, each with the same probability of success $p$.\n",
    "\n",
    "If $X$ is defined as the number of successes in $n$ trials, and each trial has a success probability $p$, then $X$ is a binomial random variable, denoted as:\n",
    "\n",
    "$$X \\sim \\text{Binomial}(n, p)$$\n",
    "\n",
    "In the binomial setting, when $n=1$, it reduces to a Bernoulli distribution.\n",
    "\n",
    "**Example:** Consider an experiment of tossing a coin 3 times. Assume $P(H)=1/3$ and we are interested in the total number of heads. Let $X$ be the total number of heads in 3 tosses. Then $X$ follows a binomial distribution:\n",
    "\n",
    "$$X \\sim \\text{Binomial} \\left(3, \\frac{1}{3} \\right)$$\n",
    "\n",
    "### 4.2.1 PMF of Binomial\n",
    "The PMF of a binomial random variable $X$ is given by:\n",
    "\n",
    "$$P(X=x) = \\binom{n}{x} p^x (1-p)^{n-x}, \\quad x=0,1,\\cdots,n$$\n",
    "\n",
    "where $\\binom{n}{x}$ is the binomial coefficient representing the number of ways to choose $x$ successes out of $n$ trials.\n",
    "\n",
    "For our coin toss example, the sample space $S$ and the corresponding probabilities $P(X=x)$ are:\n",
    "\n",
    "\\begin{align}\n",
    "S &= \\{\\text{TTT, HHH, HHT, HTH, THH, HTT, THT, TTH}\\} \\\\\n",
    "X &= 0 : P(X=0)=\\binom{3}{0} \\left(\\frac{2}{3} \\right)^3 \\\\\n",
    "X &= 1 : P(X=1)=\\binom{3}{1} \\left(\\frac{1}{3}\\right) \\left(\\frac{2}{3}\\right)^2 \\\\\n",
    "X &= 2 : P(X=2)=\\binom{3}{2} \\left(\\frac{1}{3}\\right)^2 \\left(\\frac{2}{3}\\right) \\\\\n",
    "X &= 3 : P(X=3)=\\binom{3}{3} \\left(\\frac{1}{3}\\right)^3 \\\\\n",
    "\\end{align}\n",
    "\n",
    "### 4.2.2 Expected Value and Variance of Binomial\n",
    "The expected value (mean) of a binomial random variable is:\n",
    "\n",
    "$$E(X) = np \\quad \\quad \\text{Var}(X) = np(1-p)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dc2a79",
   "metadata": {},
   "source": [
    "## 4.3 Poisson Random Variable\n",
    "<hr>\n",
    "\n",
    "The Poisson Random Variable is used to model the number of events occurring within a fixed interval of time or space, under the assumption that these events happen with a known constant rate and independently of the time since the last event.\n",
    "\n",
    "- $X$ represents the number of occurrences of events in a given time interval\n",
    "- $\\lambda$ is the average number of events in that interval\n",
    "\n",
    "$$X \\sim \\text{Poisson}(\\lambda)$$\n",
    "\n",
    "### 4.3.1 PMF of Poisson\n",
    "The PMF of a Poisson random variable $X$ is given by:\n",
    "\n",
    "$$P(X=x)= e^{-\\lambda} \\frac{\\lambda^x}{x!}$$\n",
    "\n",
    "### 4.3.2 Expected Value and Variance of Poisson\n",
    "\n",
    "$$E(X)=\\lambda \\quad \\text{Var}(X)=\\lambda$$\n",
    "\n",
    "**Example:** Consider a phone operator who on average handles 5 calls every 3 minutes. What is the probability that there will be no calls at the next minute? What is the probability that there’ll be at least 3 calls within the next 2 minutes?\n",
    "\n",
    "The rate $\\lambda$ for one minute is $\\frac{5}{3}$ calls. Let $X$ be the number of calls in one minute. Then,\n",
    "\n",
    "$$X \\sim \\text{Poisson} \\left(\\lambda=\\frac{5}{3}\\right)$$\n",
    "\n",
    "The probability of no calls is given as:\n",
    "\n",
    "$$P(X=0)=e^{\\frac{-5}{3}} \\frac{\\left(\\frac{5}{3}\\right)^0}{0!} = e^{\\left(\\frac{-5}{3}\\right)}$$\n",
    "\n",
    "The rate $\\lambda$ for two minutes is $2 \\times \\frac{5}{3} = \\frac{10}{3}$ calls. Let $Y$ be the number of calls in two minutes. Then, \n",
    "\n",
    "$$Y \\sim \\text{Poisson}\\left(\\frac{10}{3}\\right)$$\n",
    "\n",
    "The probability of at least 3 calls is given as:\n",
    "\n",
    "$$P(Y \\geq 3) = \\sum_{i=3}^\\infty e^{\\frac{-10}{3}} \\frac{\\left(\\frac{10}{3}\\right)^i}{i!}$$\n",
    "\n",
    "OR ...\n",
    "\n",
    "$$P(Y \\geq 3) = 1-P(Y=0)-P(Y=1)-P(Y=2) = 1- e^{\\frac{-10}{3}} - e^{\\frac{-10}{3}} \\frac{10}{3} - \\frac{e^{\\frac{-10}{3}} \\left(\\frac{10}{3}\\right)^2}{2} = 64.72\\%$$\n",
    "\n",
    "## 4.3.4 Poisson Approximation to the Binomial\n",
    "<hr>\n",
    "\n",
    "Let,\n",
    "\n",
    "$$X \\sim \\text{Binomial}(n, p)$$\n",
    "\n",
    "If $n$ is large and $p$ is small:\n",
    "\n",
    "\\begin{cases}\n",
    "n \\geq 30 \\\\\n",
    "p \\leq 0.05 \\\\\n",
    "\\end{cases}\n",
    "\n",
    "Then instead of using the Binomial, we can use the Poisson Approximation as:\n",
    "\n",
    "$$X \\sim \\text{Poisson}(\\lambda = n\\times p)$$\n",
    "\n",
    "**Example:** 97% of electronic messages are transmitted with no errors. What's the probability that out of 200 messages, at least 195 will be transmitted correctly.\n",
    "\n",
    "Let $X= \\text{the number of messages transmitted correctly out of 200}$\n",
    "\n",
    "\\begin{align}\n",
    "X \\sim \\text{Binomial}(200, 0.97) \\\\\n",
    "P(X \\geq 195) = \\sum_{i=195}^{200} \\binom{200}{i} (0.97)^i (0.03)^{200-i}\n",
    "\\end{align}\n",
    "\n",
    "OR ...\n",
    "\n",
    "\\begin{align}\n",
    "Y \\sim \\text{Poisson}(\\lambda=200 \\times 0.03 = 6) \\\\\n",
    "P(X \\geq 195) = P(Y \\leq 5) = \\sum_{i=0}^5 e^{-6} \\frac{6^i}{i!} = 44.56\\%\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ef00dc",
   "metadata": {},
   "source": [
    "# 4.4 Geometric Random Variable\n",
    "<hr>\n",
    "\n",
    "The Geometric Distribution models the number of trials needed to achieve the first success in a sequence of independent and identically distributed (iid) Bernoulli trials.\n",
    "\n",
    "$X$ represents the number of trials until the first success is observed, $p$ is the probability of success on any individual trial.\n",
    "\n",
    "$$X \\sim \\text{Geometric}(p)$$\n",
    "\n",
    "**Example:** Consider a coin-tossing experiment where we toss a coin until a head (H) appears, with $P(H)=2/3$.\n",
    "\n",
    "- $X$ is the number of tosses until the first head appears.\n",
    "- The sequence of tosses and the corresponding probabilities $P(X=x)$ are:\n",
    "    - 1 Toss (H): $P(H)=2/3$\n",
    "    - 2 Tosses (TH): $P(TH)=1/3 \\times 2/3$\n",
    "    - 3 Tosses (TTH): $P(TTH)=(1/3)^2 \\times 2/3$\n",
    "    - 4 Tosses (TTTH): $P(TTTH)=(1/3)^3 \\times 2/3$\n",
    "    - and so on...\n",
    "    \n",
    "*Note: The success trial is always positioned at the end of the sequence.*\n",
    "    \n",
    "### 4.4.1 PMF of Geometric\n",
    "\n",
    "$$P(X=k)=(1-p)^{k-1} \\times p, \\quad x=1, 2, \\cdots$$\n",
    "\n",
    "For $X=k$, there are $k-1$ failures before a success. The probability of failure is $1-p$\n",
    "\n",
    "### 4.4.2 Expected Value and Variance of Geometric\n",
    "\n",
    "$$E(X)=\\frac{1}{p} \\quad\\quad \\text{Var}=\\frac{1-p}{p^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dfa47b",
   "metadata": {},
   "source": [
    "# 4.5 Negative Binomial Random Variable\n",
    "<hr>\n",
    "\n",
    "The Negative Binomial Distribution can be viewed as an extension of the Geometric Distribution. It models the number of trials required to achieve a specified number of successes (rather than just the first success) in a sequence of independent and identically distributed (iid) Bernoulli trials.\n",
    "\n",
    "- $X$ denotes the number of trials needed to achieve $r$ successes.\n",
    "- $r$ is the target number of successes.\n",
    "- $p$ is the probability of success on any individual trial.\n",
    "\n",
    "$$X \\sim \\text{NegBinomial}(r, p)$$\n",
    "\n",
    "**Example:** Consider a coin-tossing experiment where we are interested in achieving $r=2$ heads (successes), with the probability of a head $P(H)=\\frac{2}{3}$.\n",
    "\n",
    "$X$ is the number of tosses until 2 heads are observed. Example sequences and probabilities:\n",
    "\n",
    "- 2 Tosses (HH): $P=\\left( \\frac{2}{3} \\right) \\left(\\frac{2}{3}\\right)$\n",
    "- 3 Tosses (HTH, THH): $P=2 \\times \\left[ \\frac{1}{3} \\left( \\frac{2}{3}\\right)^2 \\right]$\n",
    "- 4 Tosses (HTTH, THTH, TTHH): $P = 3 \\times \\left[ \\left(\\frac{1}{3}\\right)^2 \\left(\\frac{2}{3}\\right)^2 \\right]$\n",
    "- and so on ...\n",
    "\n",
    "*The distribution starts with the best-case scenario where $X=r$, indicating all trials are successful. The last success is always considered fixed in its position.*\n",
    "\n",
    "### 4.5.1 PMF of Negative Binomial\n",
    "\n",
    "$$P(X=k) = \\binom{k-1}{r-1} (1-p)^{k-r} p^r, \\quad x=r, r+1, \\cdots $$\n",
    "\n",
    "- $k$ is the total number of trials\n",
    "- $r$ is the number of successes\n",
    "- The binomial coefficient $\\binom{k-1}{r-1}$ represents the number of ways to arrange $r-1$ successes in the first $k-1$ trials\n",
    "\n",
    "### 4.5.2 Expected Value and Variance of Negative Binomial\n",
    "\n",
    "$$E(X)=\\frac{r}{p} \\quad \\quad \\text{Var}(X)= \\frac{r(1-p)}{p^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f5334f",
   "metadata": {},
   "source": [
    "# 4.6 Hypergeometric Random Variable\n",
    "<hr>\n",
    "\n",
    "The Hypergeometric Distribution models the probability of drawing a specific number of successes (e.g., red balls) without replacement from a finite population. It's often used in scenarios where the sampling doesn't allow for replacements, distinguishing it from the Binomial Distribution.\n",
    "\n",
    "- $X$: Represents the number of successes (e.g., red balls) in the sample.\n",
    "- $N$: Total number of items in the population.\n",
    "- $m$: Number of successes in the population.\n",
    "- $k$: Number of draws (sample size).\n",
    "\n",
    "$$X \\sim \\text{HyperGeo}(N, m, k)$$\n",
    "\n",
    "**Example:** Consider a box containing $N$ balls, of which $m$ are red and $N−m$ are green. Suppose we draw $k$ balls without replacement.\n",
    "\n",
    "- $X$: Number of red balls in our sample of size $k$.\n",
    "- The possible values of $X$ range from $0$ to $k$, depending on how many red balls are drawn.\n",
    "\n",
    "### 4.6.1 PMF of Hypergeometric\n",
    "\n",
    "$$P(X=x) = \\frac{\\binom{m}{x} \\binom{N-m}{k-x}}{\\binom{N}{k}}$$\n",
    "\n",
    "\\begin{cases}\n",
    "x=0,1, \\cdots n & n \\leq r \\\\\n",
    "x=0,1, \\cdots r & n \\gt r \\\\\n",
    "\\end{cases}\n",
    "\n",
    "- $X$: Number of successes (red balls) in the sample.\n",
    "- $\\binom{m}{x}$: Ways to choose $x$ successes.\n",
    "- $\\binom{N-m}{k-x}$: Ways to choose the remaining $k-x$ failures (green balls).\n",
    "- $\\binom{N}{k}$: Total ways to choose $k$ balls from $N$.\n",
    "\n",
    "### 4.6.2 Expected Value and Variance of Hypergeometric\n",
    "\n",
    "$$E(X)=\\frac{km}{N} \\quad \\quad \\text{Var}(X) = \\frac{km}{N} \\left(\\frac{N-m}{N}\\right) \\left(\\frac{N-k}{N-1}\\right)$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data Mining (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
