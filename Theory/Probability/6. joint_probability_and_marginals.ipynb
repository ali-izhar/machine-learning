{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df22561b",
   "metadata": {},
   "source": [
    "# 6. Joint Distribution Functions\n",
    "<hr>\n",
    "In an experiment, we are interested in the sample space $S$. In a disjoint distribution function, we define $x \\in \\mathbb{R}$ or $y \\in \\mathbb{R}$. However, in a joint distribution function with two simultaneous random variables or bivariate distribution, we define $(x,y) \\in \\mathbb{R}^2$ such that $f(x,y$) is the joint probability distribution function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce61a00",
   "metadata": {},
   "source": [
    "## 6.1 Joint Continuous Random Variables\n",
    "<hr>\n",
    "\n",
    "For two continuous random variables $X$ and $Y$, the joint PDF is denoted as $f_{XY}(x, y)$. It represents the density of probability at each point $(x,y)$ in the sample space.\n",
    "\n",
    "- The joint PDF is always non-negative: $f_{XY}(x,y) \\geq 0$\n",
    "- The integral of the joint PDF over the entire sample space equals 1\n",
    "\n",
    "\\begin{align}\n",
    "P\\left((x, y) \\in A \\right) &= \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} f(x, y) dx dy = 1 & \\text{joint probability} \\\\\n",
    "\\\\\n",
    "E\\left( g(x,y) \\right) &= \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} g(x,y) f(x,y) dx dy & \\text{joint expectation} \\\\\n",
    "\\\\\n",
    "F(a,b) = P(X \\leq a, Y \\leq b) &= \\int_{-\\infty}^{a} \\int_{-\\infty}^{b} f(s,t) ds dt & \\text{joint cdf} \\\\\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "## 6.2 Joint Discrete Random Variables\n",
    "<hr>\n",
    "\n",
    "For two discrete random variables $X$ and $Y$, the joint PMF is denoted as $p_{XY}(x, y)$. It represents the probability of $X$ taking some value $x$ and $Y$ taking some value $y$ simultaneously.\n",
    "\n",
    "- The joint PMF is always non-negative: $p_{XY}(x,y) \\geq 0$\n",
    "- The sum of the joint PMF over all possible values of $X$ and $Y$ equals 1\n",
    "\n",
    "\\begin{align}\n",
    "P\\left((x, y) \\in A \\right) &= \\sum_{\\forall{y}} \\sum_{\\forall{x}} f(x, y) = 1 & \\text{joint probability} \\\\\n",
    "\\\\\n",
    "E\\left( g(x,y) \\right) &= \\sum_{\\forall{y}} \\sum_{\\forall{x}} g(x,y) f(x,y) & \\text{joint expectation} \\\\\n",
    "\\\\\n",
    "F(a,b) &= P(X \\leq a, Y \\leq b) & \\text{joint cdf} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd349cc1",
   "metadata": {},
   "source": [
    "## 6.3 Marginal Distribution\n",
    "<hr>\n",
    "\n",
    "Marginal distribution focuses on the probability distribution of one or more random variables irrespective of the values of other variables. It provides insights into the distribution of individual variables within a larger multivariate distribution. It is the probability distribution for a subset of the variables within a joint distribution. For example, in a joint distribution of variables $X$ and $Y$, the marginal distribution of $X$ would describe the probability distribution of $X$ irrespective of the values of $Y$.\n",
    "\n",
    "\\begin{align}\n",
    "\\text{Discrete Case} \\\\\n",
    "P_X(x) = \\sum_{\\forall{y}} P(x,y) \\\\\n",
    "P_Y(y) = \\sum_{\\forall{x}} P(x,y) \\\\\n",
    "\\end{align}\n",
    "\n",
    "<br>\n",
    "\n",
    "\\begin{align}\n",
    "\\text{Continuous Case} \\\\\n",
    "f_X(x) = \\int_{-\\infty}^{\\infty} f(x,y) dy \\\\\n",
    "f_Y(y) = \\int_{-\\infty}^{\\infty} f(x,y) dx \\\\\n",
    "\\end{align}\n",
    "\n",
    "-\tThe marginal distributions are probability distributions.\n",
    "-\tThe marginal is a result of the joint distribution.\n",
    "-\tIf we've a joint distribution, then we can figure out the marginal distribution but not the other way around."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38ac833",
   "metadata": {},
   "source": [
    "## 6.4 Independent Random Variables\n",
    "<hr>\n",
    "\n",
    "$X$ and $Y$ are independent if the joint probability is equal to the product of the marginals.\n",
    "\n",
    "| Discrete |    | Continous|\n",
    "| --- | --- | --- |\n",
    "| $$P(x,y)=P_X(x) . P_Y(y)$$ |    | $$f(x,y) = f_X(x) . f_Y(y)$$ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bc387c",
   "metadata": {},
   "source": [
    "## 6.5 Conditional Probability\n",
    "<hr>\n",
    "\n",
    "Let $A$ and $B$ be two events. Then,\n",
    "\n",
    "\\begin{align}\n",
    "P(A \\mid B) &= \\frac{P(A \\cap B)}{P(B)} & \\text{A and B are dependent} \\\\\n",
    "\\\\\n",
    "P(A \\mid B) &= P(A) & \\text{A and B are independent} \\\\\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "*For joint distributions:*\n",
    "\n",
    "- If X and Y are discrete random variables\n",
    "\\begin{align}\n",
    "P(X=x \\mid Y=y) &= \\frac{P(X=x, Y=y)}{P_Y(Y=y)} & \\text{dependent} \\\\\n",
    "\\\\\n",
    "P(X=x \\mid Y=y) &= P_X(X=x) & \\text{independent} \\\\\n",
    "\\end{align}\n",
    "\n",
    "<br>\n",
    "\n",
    "- If X and Y are continuous random variables\n",
    "\\begin{align}\n",
    "f_{X \\mid Y}(x \\mid y) &= \\frac{f(x,y)}{f_Y(y)} & \\text{dependent} \\\\\n",
    "\\\\\n",
    "f_{X \\mid Y}(x \\mid y) &= f_X(x) & \\text{independent} \\\\\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d2433f",
   "metadata": {},
   "source": [
    "## 6.6 Sum of Independent Random Variables\n",
    "<hr>\n",
    "\n",
    "Let $X$ and $Y$ be two independent random variables and let $Z=X+Y$. Find the pdf of $Z$, or $f_Z(z) = ?$\n",
    "\n",
    "Let the pdfs of $X$ and $Y$ be $f_X(x)$ and $f_Y(y)$ respectively. Then the pdf of $Z$ is the derivative of its cdf. The cdf of $Z$ (denoted as a below) is given as:\n",
    "\n",
    "$$P(X+Y \\leq a) = \\int_{X+Y \\leq a} \\int f(x,y) dx dy$$\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"media/sum_of_ind.png\" width=300>\n",
    "    <figcaption>Plotting $X$ and $Y$</figcaption>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "Since $X$ and $Y$ are independent:\n",
    "\n",
    "\\begin{align}\n",
    "P(X+Y \\leq a) &= \\int_{X+Y \\leq a} \\int f_X(x) f_Y(y) dx dy \\\\\n",
    "&= \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{a-Y} f_X(x) f_Y(y) dx dy \\\\\n",
    "&= \\int_{-\\infty}^{\\infty} f_Y(y) \\int_{-\\infty}^{a-Y} f_X(x) f_Y(y) dx dy \\\\\n",
    "F_{X+Y}(a) &= \\int_{-\\infty}^{\\infty} f_Y(y) F_X(a-y) dy \\\\\n",
    "f_{X+Y}(a) &= \\frac{d}{da} \\int_{-\\infty}^{\\infty} f_Y(y) F_X(a-y) dy \\\\\n",
    "&= \\int_{-\\infty}^{\\infty} f_Y(y) \\frac{d}{da} F_X(a-y) dy \\\\\n",
    "f_{X+Y}(a) &= \\int_{-\\infty}^{\\infty} f_Y(y) f_X(a-y) dy \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9598348b",
   "metadata": {},
   "source": [
    "## 6.7 Expectation of Sums of Random Variables\n",
    "<hr>\n",
    "\n",
    "$$E(X + Y) = E(X) + E(Y)$$\n",
    "\n",
    "*Proof.*\n",
    "\n",
    "\\begin{align}\n",
    "E(X+Y) &= \\int \\int (X+Y) f(x,y) dx dy \\\\\n",
    "&= \\int \\int X f(x,y) dx dy + \\int \\int Y f(x,y) dx dy \\\\\n",
    "&= \\int X \\int f(x,y) dy dx + \\int Y \\int f(x,y) dx dy \\\\\n",
    "&= \\int X f_X(x) dx + \\int Y f_Y(y) dy \\\\\n",
    "&= E(X) + E(Y)\n",
    "\\end{align}\n",
    "\n",
    "In general,\n",
    "\n",
    "$$E(X_1 + X_2 + \\cdots + X_n) = E(X_1) + E(X_2) + \\cdots + E(X_n) = \\sum_{i=1}^n E(X_i)$$\n",
    "\n",
    "However,\n",
    "\n",
    "$$E\\left( \\sum_{i=1}^\\infty X_i \\right) \\neq \\sum_{i=1}^\\infty E(X_i)$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data Mining (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
